{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# File processor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "csv_decoder.py is a packaged version of Josh's methods reading .csv generated by his c++ showering code.\n",
    "save_and_load.py specifically saves and loads all essential lists/images used in the analysis to np.save formats.\n",
    "\n",
    "This notebook shows the example use of methods in csv_decoder.py and save_and_load.py. It reads .csv files containing particle eta, phi, pt, ... produced by Josh's showering program, performs fast detector simulation to generate detector & jet images, and saves to faster np.save format. The save(), load() and load_cluster() methods are saved in "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#TODO store all variables from skype and p3 of paper\n",
    "\n",
    "# Import local libraries\n",
    "import csv_decoder\n",
    "import save_and_load\n",
    "import importlib\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jet and event image setting\n",
    "width = 40\n",
    "height = 40 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading hj events\n",
      "Loading .csv event files from /home/ffu/higgs-classifier/showering/ggh-hj-csv/ containing '.csv'\n",
      "List of files is: ['13701_seed_66352.csv', '21491_seed_50579.csv', '10821_seed_37915.csv', '25036_seed_78488.csv', '10706_seed_50891.csv', '32446_seed_7248.csv', '19981_seed_26367.csv', '11204_seed_61004.csv', '8907_seed_85653.csv', '11716_seed_94420.csv', '27338_seed_72629.csv', '2147_seed_48618.csv', '3841_seed_34994.csv', '16660_seed_12854.csv', '26068_seed_52269.csv', '84_seed_55366.csv', '527_seed_878.csv', '11277_seed_59254.csv', '30639_seed_5902.csv', '2131_seed_29459.csv', '19998_seed_63437.csv', '12396_seed_95743.csv', '29564_seed_30321.csv', '31653_seed_14633.csv', '22123_seed_29941.csv', '946_seed_36549.csv', '15844_seed_79439.csv', '26040_seed_14541.csv', '8973_seed_457.csv', '31789_seed_36820.csv', '12510_seed_61346.csv', '20393_seed_74068.csv', '32500_seed_291.csv', '23341_seed_102774.csv', '13584_seed_94711.csv', '22335_seed_21109.csv', '20740_seed_23852.csv', '17679_seed_39739.csv', '23532_seed_32822.csv', '25731_seed_20341.csv', '1715_seed_57227.csv', '9295_seed_46731.csv', '12404_seed_79706.csv', '11758_seed_24609.csv', '5241_seed_96625.csv', '516_seed_8634.csv', '18163_seed_43473.csv', '27581_seed_49749.csv', '27173_seed_5032.csv', '7513_seed_100663.csv']\n",
      "Currently reading: 13701_seed_66352.csv\n",
      "1files processed.\n",
      "Currently reading: 21491_seed_50579.csv\n",
      "2files processed.\n",
      "Currently reading: 10821_seed_37915.csv\n",
      "3files processed.\n",
      "Currently reading: 25036_seed_78488.csv\n",
      "4files processed.\n",
      "Currently reading: 10706_seed_50891.csv\n",
      "5files processed.\n",
      "Currently reading: 32446_seed_7248.csv\n",
      "6files processed.\n",
      "Currently reading: 19981_seed_26367.csv\n",
      "7files processed.\n",
      "Currently reading: 11204_seed_61004.csv\n",
      "8files processed.\n",
      "Currently reading: 8907_seed_85653.csv\n",
      "9files processed.\n",
      "Currently reading: 11716_seed_94420.csv\n",
      "10files processed.\n",
      "Currently reading: 27338_seed_72629.csv\n",
      "11files processed.\n",
      "Currently reading: 2147_seed_48618.csv\n",
      "12files processed.\n",
      "Currently reading: 3841_seed_34994.csv\n",
      "13files processed.\n",
      "Currently reading: 16660_seed_12854.csv\n",
      "14files processed.\n",
      "Currently reading: 26068_seed_52269.csv\n",
      "15files processed.\n",
      "Currently reading: 84_seed_55366.csv\n",
      "16files processed.\n",
      "Currently reading: 527_seed_878.csv\n",
      "17files processed.\n",
      "Currently reading: 11277_seed_59254.csv\n",
      "18files processed.\n",
      "Currently reading: 30639_seed_5902.csv\n",
      "19files processed.\n",
      "Currently reading: 2131_seed_29459.csv\n",
      "20files processed.\n",
      "Currently reading: 19998_seed_63437.csv\n",
      "21files processed.\n",
      "Currently reading: 12396_seed_95743.csv\n",
      "22files processed.\n",
      "Currently reading: 29564_seed_30321.csv\n",
      "23files processed.\n",
      "Currently reading: 31653_seed_14633.csv\n",
      "24files processed.\n",
      "Currently reading: 22123_seed_29941.csv\n",
      "25files processed.\n",
      "Currently reading: 946_seed_36549.csv\n",
      "26files processed.\n",
      "Currently reading: 15844_seed_79439.csv\n",
      "27files processed.\n",
      "Currently reading: 26040_seed_14541.csv\n",
      "28files processed.\n",
      "Currently reading: 8973_seed_457.csv\n",
      "29files processed.\n",
      "Currently reading: 31789_seed_36820.csv\n",
      "30files processed.\n",
      "Currently reading: 12510_seed_61346.csv\n",
      "31files processed.\n",
      "Currently reading: 20393_seed_74068.csv\n",
      "32files processed.\n",
      "Currently reading: 32500_seed_291.csv\n",
      "33files processed.\n",
      "Currently reading: 23341_seed_102774.csv\n",
      "34files processed.\n",
      "Currently reading: 13584_seed_94711.csv\n",
      "35files processed.\n",
      "Currently reading: 22335_seed_21109.csv\n",
      "36files processed.\n",
      "Currently reading: 20740_seed_23852.csv\n",
      "37files processed.\n",
      "Currently reading: 17679_seed_39739.csv\n",
      "38files processed.\n",
      "Currently reading: 23532_seed_32822.csv\n",
      "39files processed.\n",
      "Currently reading: 25731_seed_20341.csv\n",
      "40files processed.\n",
      "Currently reading: 1715_seed_57227.csv\n",
      "41files processed.\n",
      "Currently reading: 9295_seed_46731.csv\n",
      "42files processed.\n",
      "Currently reading: 12404_seed_79706.csv\n",
      "43files processed.\n",
      "Currently reading: 11758_seed_24609.csv\n",
      "44files processed.\n",
      "Currently reading: 5241_seed_96625.csv\n",
      "45files processed.\n",
      "Currently reading: 516_seed_8634.csv\n",
      "46files processed.\n",
      "Currently reading: 18163_seed_43473.csv\n",
      "47files processed.\n",
      "Currently reading: 27581_seed_49749.csv\n",
      "48files processed.\n",
      "Currently reading: 27173_seed_5032.csv\n",
      "49files processed.\n",
      "Currently reading: 7513_seed_100663.csv\n",
      "50files processed.\n",
      "Loading vh events\n",
      "Loading .csv event files from /home/ffu/higgs-classifier/showering/vh-csv containing '.csv'\n",
      "List of files is: ['8428_seed_68013.csv', '7613_seed_66303.csv', '9039_seed_77679.csv', '32401_seed_48636.csv', '16757_seed_98327.csv', '16066_seed_52266.csv', '25330_seed_61560.csv', '19264_seed_58507.csv', '2411_seed_99381.csv', '29515_seed_43446.csv', '9236_seed_81610.csv', '12001_seed_53133.csv', '26687_seed_4758.csv', '12813_seed_17599.csv', '8632_seed_20782.csv', '3820_seed_84913.csv', '1033_seed_35324.csv', '4118_seed_58301.csv', '4223_seed_81883.csv', '476_seed_36175.csv', '6619_seed_101995.csv', '2811_seed_66470.csv', '14887_seed_16588.csv', '9230_seed_2421.csv', '25937_seed_26497.csv', '2827_seed_88475.csv', '18159_seed_85261.csv', '13005_seed_67828.csv', '21187_seed_78280.csv', '31340_seed_10390.csv', '18518_seed_63121.csv', '17392_seed_65445.csv', '27818_seed_80027.csv', '19396_seed_92933.csv', '6011_seed_78062.csv', '6668_seed_69947.csv', '29374_seed_40835.csv', '9889_seed_102065.csv', '20677_seed_12811.csv', '7749_seed_75171.csv', '19995_seed_46902.csv', '32070_seed_77740.csv', '23690_seed_55522.csv', '4993_seed_18868.csv', '23258_seed_36847.csv', '12134_seed_81688.csv', '31691_seed_85450.csv', '220_seed_59440.csv', '16753_seed_37474.csv', '7132_seed_21785.csv']\n",
      "Currently reading: 8428_seed_68013.csv\n",
      "1files processed.\n",
      "Currently reading: 7613_seed_66303.csv\n",
      "2files processed.\n",
      "Currently reading: 9039_seed_77679.csv\n",
      "3files processed.\n",
      "Currently reading: 32401_seed_48636.csv\n",
      "4files processed.\n",
      "Currently reading: 16757_seed_98327.csv\n",
      "5files processed.\n",
      "Currently reading: 16066_seed_52266.csv\n",
      "6files processed.\n",
      "Currently reading: 25330_seed_61560.csv\n",
      "7files processed.\n",
      "Currently reading: 19264_seed_58507.csv\n",
      "8files processed.\n",
      "Currently reading: 2411_seed_99381.csv\n",
      "9files processed.\n",
      "Currently reading: 29515_seed_43446.csv\n",
      "10files processed.\n",
      "Currently reading: 9236_seed_81610.csv\n",
      "11files processed.\n",
      "Currently reading: 12001_seed_53133.csv\n",
      "12files processed.\n",
      "Currently reading: 26687_seed_4758.csv\n",
      "13files processed.\n",
      "Currently reading: 12813_seed_17599.csv\n",
      "14files processed.\n",
      "Currently reading: 8632_seed_20782.csv\n",
      "15files processed.\n",
      "Currently reading: 3820_seed_84913.csv\n",
      "16files processed.\n",
      "Currently reading: 1033_seed_35324.csv\n",
      "17files processed.\n",
      "Currently reading: 4118_seed_58301.csv\n",
      "18files processed.\n",
      "Currently reading: 4223_seed_81883.csv\n",
      "19files processed.\n",
      "Currently reading: 476_seed_36175.csv\n",
      "20files processed.\n",
      "Currently reading: 6619_seed_101995.csv\n",
      "21files processed.\n",
      "Currently reading: 2811_seed_66470.csv\n",
      "22files processed.\n",
      "Currently reading: 14887_seed_16588.csv\n",
      "23files processed.\n",
      "Currently reading: 9230_seed_2421.csv\n",
      "24files processed.\n",
      "Currently reading: 25937_seed_26497.csv\n",
      "25files processed.\n",
      "Currently reading: 2827_seed_88475.csv\n",
      "26files processed.\n",
      "Currently reading: 18159_seed_85261.csv\n",
      "27files processed.\n",
      "Currently reading: 13005_seed_67828.csv\n",
      "28files processed.\n",
      "Currently reading: 21187_seed_78280.csv\n",
      "29files processed.\n",
      "Currently reading: 31340_seed_10390.csv\n",
      "30files processed.\n",
      "Currently reading: 18518_seed_63121.csv\n",
      "31files processed.\n",
      "Currently reading: 17392_seed_65445.csv\n",
      "32files processed.\n",
      "Currently reading: 27818_seed_80027.csv\n",
      "33files processed.\n",
      "Currently reading: 19396_seed_92933.csv\n",
      "34files processed.\n",
      "Currently reading: 6011_seed_78062.csv\n",
      "35files processed.\n",
      "Currently reading: 6668_seed_69947.csv\n",
      "36files processed.\n",
      "Currently reading: 29374_seed_40835.csv\n",
      "37files processed.\n",
      "Currently reading: 9889_seed_102065.csv\n",
      "38files processed.\n",
      "Currently reading: 20677_seed_12811.csv\n",
      "39files processed.\n",
      "Currently reading: 7749_seed_75171.csv\n",
      "40files processed.\n",
      "Currently reading: 19995_seed_46902.csv\n",
      "41files processed.\n",
      "Currently reading: 32070_seed_77740.csv\n",
      "42files processed.\n",
      "Currently reading: 23690_seed_55522.csv\n",
      "43files processed.\n",
      "Currently reading: 4993_seed_18868.csv\n",
      "44files processed.\n",
      "Currently reading: 23258_seed_36847.csv\n",
      "45files processed.\n",
      "Currently reading: 12134_seed_81688.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46files processed.\n",
      "Currently reading: 31691_seed_85450.csv\n",
      "47files processed.\n",
      "Currently reading: 220_seed_59440.csv\n",
      "48files processed.\n",
      "Currently reading: 16753_seed_37474.csv\n",
      "49files processed.\n",
      "Currently reading: 7132_seed_21785.csv\n",
      "50files processed.\n"
     ]
    }
   ],
   "source": [
    "# Reading in custom showered files;\n",
    "# This read produces event_list (collection of raw vectors) and event images\n",
    "\n",
    "# This will be used to test saving mechanisms.\n",
    "\n",
    "print('Loading hj events')\n",
    "hj_event_list,hj_mass_list,hj_image_list, hj_higgs_list, hj_weight_list, num_hj_files = \\\n",
    "    csv_decoder.load_events(path=\"/home/ffu/higgs-classifier/showering/ggh-hj-csv/\",\\\n",
    "                contains=\".csv\",pt_cut=1, width=width, height=height)\n",
    "print('Loading vh events')\n",
    "vh_event_list,vh_mass_list,vh_image_list, vh_higgs_list, vh_weight_list, num_vh_files = \\\n",
    "    csv_decoder.load_events(path=\"/home/ffu/higgs-classifier/showering/vh-csv\",\\\n",
    "                contains=\".csv\",pt_cut=1, width=width, height=height)\n",
    "\n",
    "# TEMP: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.87976e+01  1.60030e-01  1.44452e+00  1.39570e-01 -2.11000e+02\n",
      "   1.00000e+00]\n",
      " [ 2.19699e-01  6.45319e-02  9.38926e-01  0.00000e+00  2.20000e+01\n",
      "   0.00000e+00]]\n"
     ]
    }
   ],
   "source": [
    "print(vh_event_list[0][::100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset sizes:\n",
      "75011 54279\n",
      "Clustering\n",
      "Reclustering\n",
      "Producing jet images\n",
      "Number of events with only one constituent in leading jet: 22\n",
      "Number of events with only one constituent in leading jet: 8\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(csv_decoder)\n",
    "\n",
    "# Check size of dataset\n",
    "print(\"Dataset sizes:\")\n",
    "print(len(vh_mass_list),len(hj_mass_list))\n",
    "\n",
    "\n",
    "# This is not used\n",
    "vh_mass_window = np.logical_and(np.array(vh_mass_list) > 115,np.array(vh_mass_list) < 135)\n",
    "\n",
    "# Cluster events_lists into jets. The results are named vh/hj_event_list_clustered\n",
    "print('Clustering')\n",
    "vh_event_list_clustered = csv_decoder.cluster_event(vh_event_list)\n",
    "hj_event_list_clustered = csv_decoder.cluster_event(hj_event_list)\n",
    "\n",
    "# Reclustering the events (i.e. clustering within events)\n",
    "print('Reclustering')\n",
    "vh_reclustered, = csv_decoder.recluster_event(vh_event_list_clustered, vh_higgs_list)\n",
    "hj_reclustered, = csv_decoder.recluster_event(hj_event_list_clustered, hj_higgs_list)\n",
    "\n",
    "# Produce jet images, the zero-center and normalize\n",
    "print('Producing jet images')\n",
    "vh_recluster_images = csv_decoder.return_jet_image_list(vh_event_list,\n",
    "                                                           vh_reclustered,0.8, width=width, height=height)\n",
    "hj_recluster_images = csv_decoder.return_jet_image_list(hj_event_list,\n",
    "                                                           hj_reclustered,0.8, width=width, height=height)\n",
    "\n",
    "# Zero centering and normalizing\n",
    "vh_image_list, hj_image_list = csv_decoder.zero_center_and_normalize_pair(vh_image_list,hj_image_list)\n",
    "vh_recluster_images, hj_recluster_images = csv_decoder.zero_center_and_normalize_pair(vh_recluster_images, hj_recluster_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(save_and_load)\n",
    "save_and_load.save_binary('vh-hj', vh_event_list, hj_event_list, vh_mass_list, hj_mass_list,\\\n",
    "        vh_higgs_list, hj_higgs_list, vh_weight_list, hj_weight_list, vh_image_list, hj_image_list ,\\\n",
    "        vh_recluster_images, hj_recluster_images, name_1='vh', name_2='hj')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading in event files from a given folder.\n",
    "# TODO: update!\n",
    "def generate_images(path, contains=\".csv\" ,max_read=float('inf'), max_files=float('inf'), \n",
    "                    weighted=0, pt_cut=1, width_param=width, height_param=height):\n",
    "    # Reading in files\n",
    "    event_list,mass_list,image_list,num_files = csv_decoder.load_events(\n",
    "            path = path, \n",
    "            contains = contains, \n",
    "            max_read = max_read, \n",
    "            max_files = max_files, \n",
    "            weighted = weighted, \n",
    "            pt_cut = 1, width=width_param, height=height_param)\n",
    "\n",
    "    # Cluster events_lists into jets. The results are named background/signal_event_list_clustered\n",
    "    print('Clustering')\n",
    "    event_list_clustered = csv_decoder.cluster_event(event_list)\n",
    "\n",
    "    # Reclustering the events (i.e. clustering within events)\n",
    "    print('Reclustering')\n",
    "    reclustered = csv_decoder.recluster_event(event_list_clustered)\n",
    "\n",
    "    # Produce jet images, the zero-center and normalize\n",
    "    print('Producing jet images')\n",
    "    recluster_images = csv_decoder.return_fine_image_list_reclustered(event_list,\n",
    "                                                           reclustered,0.8, width=width, height=height)\n",
    "    # Weight calculation, UNFINISHED!\n",
    "    weight = -1\n",
    "    \n",
    "    return event_list, mass_list, weight, image_list, recluster_images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Processing VBF and VH samples\n",
    "vbf_event_list, vbf_mass_list, vbf_weight, vbf_image_list, vbf_recluster_images = generate_images(path='/home/ffu/higgs-classifier/samples/vbf-csv/')\n",
    "vh_event_list, vh_mass_list, vh_weight, vh_image_list, vh_recluster_images = generate_images(path='/home/ffu/higgs-classifier/samples/vh-csv/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zero-centering and normalizing\n",
    "#vbf_image_list, vh_image_list = csv_decoder.zero_center_and_normalize_pair(vbf_image_list, vh_image_list)\n",
    "(vbf_image_list, vh_image_list) = csv_decoder.zero_center_and_normalize((vbf_image_list, vh_image_list))\n",
    "print(len(vbf_event_list))\n",
    "print(len(vh_event_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading in Josh's files; background is a single large file (pT cut must be 1 here for Josh's sample)\n",
    "# This read produces event_list (collection of raw vectors) and event images\n",
    "#\n",
    "# This will be used to test saving mechanisms.\n",
    "#\n",
    "# NOTE\n",
    "# THIS PART IS NO LONGER COMPATIBLE WITH NEW ANALYSIS CODE! NEW CODE READS WEIGHT AND HIGGS JET INFO.\n",
    "print('Loading background events')\n",
    "background_event_list,background_mass_list,background_image_list,num_background_files = \\\n",
    "    csv_decoder.load_events(path=\"/data1/users/jzlin/MLM/background_7413/\",\\\n",
    "                contains=\"actual_actual\",max_files=1,pt_cut=1, width=width, height=height)\n",
    "num_background_files = 15693\n",
    "\n",
    "print('Loading signal events')\n",
    "signal_event_list,signal_mass_list,signal_image_list,num_signal_files = \\\n",
    "    csv_decoder.load_events(path=\"/data1/users/jzlin/MLM/heavy_signal/\",\\\n",
    "                contains=\"actual_signal\",max_read = len(background_event_list),pt_cut=1, width=width, height=height)\n",
    "\n",
    "# TEMP: \n",
    "\n",
    "# Check size of dataset\n",
    "print(len(background_mass_list),len(signal_mass_list))\n",
    "\n",
    "\n",
    "# This is not used\n",
    "background_mass_window = np.logical_and(np.array(background_mass_list) > 115,np.array(background_mass_list) < 135)\n",
    "\n",
    "# Cluster events_lists into jets. The results are named background/signal_event_list_clustered\n",
    "print('Clustering')\n",
    "background_event_list_clustered = csv_decoder.cluster_event(background_event_list)\n",
    "signal_event_list_clustered = csv_decoder.cluster_event(signal_event_list)\n",
    "\n",
    "# Reclustering the events (i.e. clustering within events)\n",
    "print('Reclustering')\n",
    "background_reclustered = csv_decoder.recluster_event(background_event_list_clustered)\n",
    "signal_reclustered = csv_decoder.recluster_event(signal_event_list_clustered)\n",
    "\n",
    "# Produce jet images, the zero-center and normalize\n",
    "print('Producing jet images')\n",
    "background_recluster_images = csv_decoder.return_fine_image_list_reclustered(background_event_list,\n",
    "                                                           background_reclustered,0.8, width=width, height=height)\n",
    "signal_recluster_images = csv_decoder.return_fine_image_list_reclustered(signal_event_list,\n",
    "                                                           signal_reclustered,0.8, width=width, height=height)\n",
    "\n",
    "# Zero centering and normalizing\n",
    "background_image_list, signal_image_list = csv_decoder.zero_center_and_normalize_pair(background_image_list,signal_image_list)\n",
    "background_recluster_images, signal_recluster_images = csv_decoder.zero_center_and_normalize_pair(background_recluster_images, signal_recluster_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weight calculation for Josh's sample\n",
    "backgroundCross = 2.048e-06 # Cross-section of processes in millibarns, NOT USED\n",
    "\n",
    "actual_background_cross=2.84e-9 # In barns, used in background weight\n",
    "average_number_accepted=2162 # Used in background weight\n",
    "\n",
    "actual_signal_cross = np.average([1.738e-14,1.7277e-14]) # Used in signal weight\n",
    "signal_accepted = np.average([8708-189,8827-172]) # Used in signal weight \n",
    "\n",
    "background_weight = actual_background_cross*35.9*1e15/(average_number_accepted*num_background_files)\n",
    "signal_weight = actual_signal_cross*35.9*1e15/(signal_accepted*num_signal_files)\n",
    "# Weight is calculated by cross section * 35.9(integrated luminosity) * 1e15 / # total event \n",
    "# cross_sec*L_int = dN/dt\n",
    "\n",
    "# Testing saving time for Josh's samples\n",
    "# Time: 19.26s\n",
    "save_and_load.save('hbb-qcd', background_event_list, signal_event_list, background_mass_list, signal_mass_list,\\\n",
    "        background_weight, signal_weight, background_image_list, signal_image_list,\\\n",
    "        background_recluster_images, signal_recluster_images)\n",
    "\n",
    "# Testing reading for .npy files of Josh's samples\n",
    "new_background_event_list, new_signal_event_list, new_background_mass_list, new_signal_mass_list,\\\n",
    "        new_background_weight, new_signal_weight, new_background_image_list, new_signal_image_list,\\\n",
    "        new_background_recluster_images, new_signal_recluster_images = save_and_load.load('hbb-qcd')\n",
    "print(np.array_equal(new_background_mass_list, background_mass_list))\n",
    "print(np.array_equal(new_signal_mass_list, signal_mass_list))\n",
    "print(np.array_equal(new_background_weight, background_weight))\n",
    "print(np.array_equal(new_signal_weight, signal_weight))\n",
    "print(np.array_equal(new_background_image_list, background_image_list))\n",
    "print(np.array_equal(new_signal_image_list, signal_image_list))\n",
    "print(np.array_equal(new_background_recluster_images, background_recluster_images))\n",
    "print(np.array_equal(new_signal_recluster_images, signal_recluster_images))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 Keras",
   "language": "python",
   "name": "python_3_keras"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
