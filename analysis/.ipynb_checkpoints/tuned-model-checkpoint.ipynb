{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INITIALISATIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "code_folding": []
   },
   "source": [
    "This program loads in .npy files produced by file-processing.ipynb and performs CNN classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Initializing TF and Keras\n",
    "from __future__ import division\n",
    "import sys\n",
    "\n",
    "# Clear logs from previous runs\n",
    "!rm -rf ./tensorboard-logs/\n",
    "\n",
    "# Notes ############################################################################\n",
    "#\n",
    "# 1.\n",
    "#     Normal tf import is disabled to solve ray.tune pickling error\n",
    "#     import tensorflow as tf \n",
    "# 2.\n",
    "#     To automatically view training result with tensorboard, use \n",
    "#         tensorboard --logdir ~/ray_results\n",
    "# 3.\n",
    "#     Prints the devices in use, deleted since global tf import is disabled\n",
    "#     from tensorflow.python.client import device_lib\n",
    "#         print(device_lib.list_local_devices())\n",
    "#         print(\"Tensorflow version is\")\n",
    "#         print(tf.__version__)\n",
    "#         print(\"Keras version is\")\n",
    "#         print(keras.__version__)\n",
    "# 4.\n",
    "#     To use only GPU3, run commands using:\n",
    "#         with tf.device('/device:XLA_GPU:3'):\n",
    "# 5.\n",
    "#     To use tensorboard, enable extension and add logging folder production:\n",
    "#         import datetime\n",
    "#         %load_ext tensorboard\n",
    "#         log_dir=\"tensorboard-logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras version: 2.2.4-tf\n"
     ]
    }
   ],
   "source": [
    "# Importing tensorflow.keras \n",
    "import tensorflow as tf\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Activation, Conv2D, MaxPooling2D, Flatten, Dropout\n",
    "from tensorflow.keras.layers import Lambda\n",
    "from tensorflow.keras import backend as K\n",
    "from keras.engine.topology import Layer\n",
    "from keras.layers.merge import concatenate\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from keras.utils.io_utils import HDF5Matrix # NECESSARY\n",
    "from tensorflow.keras.layers import SpatialDropout2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.layers import Concatenate\n",
    "print('Keras version: ' + tensorflow.keras.__version__)\n",
    "\n",
    "# Import basic libraries\n",
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "import os\n",
    "import re\n",
    "import matplotlib\n",
    "import time\n",
    "import pickle \n",
    "import shutil\n",
    "\n",
    "# Import HDF5 to use disk for large dataset\n",
    "import h5py\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.path as mpath\n",
    "import matplotlib.lines as mlines\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.pyplot import cm\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from matplotlib.collections import PatchCollection\n",
    "\n",
    "import scipy\n",
    "import scipy.optimize as opt\n",
    "from scipy.interpolate import griddata\n",
    "from scipy import interpolate\n",
    "from scipy.optimize import least_squares\n",
    "\n",
    "# Import local libraries\n",
    "from substructure import * # Jet substructure variables\n",
    "import save_and_load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANALYSIS FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [
     0,
     38,
     49,
     89,
     103,
     117
    ]
   },
   "outputs": [],
   "source": [
    "def generate_real_SIC(expect,predict,masses,quality=1,verbose=False):\n",
    "    if background_weight<0:\n",
    "        raise Exception('Negative background weight. Please update .npy file!')\n",
    "    if signal_weight<0:\n",
    "        raise Exception('Negative signal weight. Please update .npy file!')\n",
    "        \n",
    "    to_sort = np.flip(np.array(sorted(np.vstack((expect,predict.flatten(),masses)).transpose(), key=lambda x: x[1])),0)\n",
    "    efficiency = []; signal_eff = [];\n",
    "    total_signal = np.sum(to_sort[:,0])\n",
    "    for i in range(int(0.05*len(to_sort)),len(to_sort),quality*10):\n",
    "        background_mass_binned,bins = np.histogram(to_sort[:i+1,2][to_sort[:i+1,0]==0],bins=np.arange(50,197,7))\n",
    "        signal_mass_binned,bins = np.histogram(to_sort[:i+1,2][to_sort[:i+1,0]==1],bins=np.arange(50,197,7))\n",
    "        log_likelihood = 0; baseLL = 0; \n",
    "        signal_eff.append(np.sum(to_sort[:i+1,0])/total_signal)\n",
    "        test_LL_vs_SS = []\n",
    "        for signal_strength in np.arange(1,5,quality/1000):\n",
    "            log_likelihood = 0;\n",
    "            for k in range(len(bins)-1):\n",
    "                expected = background_weight*background_mass_binned[k]+signal_weight*signal_strength*signal_mass_binned[k]\n",
    "                observed = background_weight*background_mass_binned[k]+signal_weight*signal_mass_binned[k]\n",
    "                if (expected <= 0):\n",
    "                    pass\n",
    "                else:\n",
    "                    log_likelihood = log_likelihood + observed*math.log(expected) - expected\n",
    "            if signal_strength == 1:\n",
    "                baseLL = log_likelihood\n",
    "            test_LL_vs_SS.append(log_likelihood)\n",
    "            if log_likelihood < baseLL-1/2:\n",
    "                efficiency.append(1/(signal_strength-1))\n",
    "                break\n",
    "            if signal_strength > 3:\n",
    "                efficiency.append(1/2)\n",
    "                break\n",
    "    max_eff = np.max(efficiency)\n",
    "    max_cut = to_sort[efficiency.index(max_eff),1]\n",
    "    print(\"base efficiency : \" + str(float(efficiency[-1])))\n",
    "    efficiency = np.array(efficiency)/float(efficiency[-1])\n",
    "    max_eff = np.max(efficiency)\n",
    "    print(\"Max SI of \" + str(max_eff) + \" at cut \" + str(max_cut))\n",
    "    return(efficiency,signal_eff)\n",
    "\n",
    "def find_highest_SIC(expect,predict,quality=100,verbose=False):\n",
    "    to_sort = np.flip(np.array(sorted(np.vstack((expect,predict.flatten())).transpose(), key=lambda x: x[1])),0)\n",
    "    total_signal = np.sum(to_sort[:,0])\n",
    "    efficiency = []\n",
    "    for i in range(int(0.05*len(to_sort)),len(to_sort)): # generate a int range scanning over 95% of all samples??\n",
    "        signal_eff_temp = np.sum(to_sort[:i+1,0])/total_signal\n",
    "        background_eff_temp = (i+1-np.sum(to_sort[:i+1,0]))/(len(to_sort)-total_signal)\n",
    "        efficiency.append((signal_eff_temp)/((background_eff_temp)**(1/2)))\n",
    "    max_eff = np.max(efficiency)\n",
    "    return(max_eff)\n",
    "\n",
    "def find_highest_SIC_binned(expect,predict,masses):\n",
    "    if background_weight<0:\n",
    "        raise Exception('Negative background weight. Please update .npy file!')\n",
    "    if signal_weight<0:\n",
    "        raise Exception('Negative signal weight. Please update .npy file!')\n",
    "        \n",
    "    bins = np.arange(50,197,7)\n",
    "    efficiency = []    \n",
    "    sigmas = []\n",
    "    for i in np.arange(0,0.9,0.05):\n",
    "        #res = least_squares(lambda x : log_like(x,masses[np.logical_and(predict.flatten() >= i,expect == 0)],\n",
    "        #                                        masses[np.logical_and(predict.flatten() >= i,expect == 1)]),x0=1)\n",
    "\n",
    "        #i is the cut on the machine learning\n",
    "        kept_back = masses[np.logical_and(predict.flatten() >= i,expect == 0)]\n",
    "        kept_signal = masses[np.logical_and(predict.flatten() >= i,expect == 1)]\n",
    "        j_array = []\n",
    "        for j in np.arange(1,25,0.5):\n",
    "            #print log_like(j,kept_back,kept_signal)\n",
    "            if log_like(j,kept_back,kept_signal) > log_like(1,kept_back,kept_signal)+0.5:\n",
    "                j_array.append(j-1)\n",
    "                break\n",
    "            if j >20:\n",
    "                j_array.append(20)\n",
    "                break\n",
    "        print(j_array,i)\n",
    "        sigmas.append(1/np.min(j_array))\n",
    "        \n",
    "    max_eff = np.max(sigmas)\n",
    "    return(max_eff)\n",
    "\n",
    "def generateSIC(expect,predict,quality=100,verbose=False):\n",
    "    to_sort = np.flip(np.array(sorted(np.vstack((expect,predict.flatten())).transpose(), key=lambda x: x[1])),0)\n",
    "    total_signal = np.sum(to_sort[:,0])\n",
    "    efficiency = []; signal_eff = []\n",
    "    for i in range(int(0.05*len(to_sort)),len(to_sort)):\n",
    "        signal_eff_temp = np.sum(to_sort[:i+1,0])/total_signal\n",
    "        background_eff_temp = (i+1-np.sum(to_sort[:i+1,0]))/(len(to_sort)-total_signal)\n",
    "        signal_eff.append(signal_eff_temp)\n",
    "        efficiency.append((signal_eff_temp)/((background_eff_temp)**(1/2)))\n",
    "    max_eff = np.max(efficiency)\n",
    "    max_cut = to_sort[efficiency.index(max_eff),1]\n",
    "    print(\"Max SI of \" + str(max_eff) + \" at cut \" + str(max_cut))\n",
    "    return(efficiency,signal_eff)\n",
    "\n",
    "def log_like(signal_strength,background_mass_list,signal_mass_list):\n",
    "    if background_weight<0:\n",
    "        raise Exception('Negative background weight. Please update .npy file!')\n",
    "    if signal_weight<0:\n",
    "        raise Exception('Negative signal weight. Please update .npy file!')\n",
    "        \n",
    "    log_likelihood = 0\n",
    "    background_mass_binned,bins = np.histogram(background_mass_list,bins=np.arange(50,197,7))\n",
    "    signal_mass_binned,bins = np.histogram(signal_mass_list,bins=np.arange(50,197,7))\n",
    "    for i in range(len(bins)-1):\n",
    "        expected = background_weight*background_mass_binned[i]+signal_weight*signal_strength*signal_mass_binned[i]\n",
    "        observed = background_weight*background_mass_binned[i]+signal_weight*signal_mass_binned[i]\n",
    "        if (expected <= 0):\n",
    "            return float(\"inf\")\n",
    "        log_likelihood = log_likelihood + observed*math.log(expected) - expected\n",
    "    return -log_likelihood\n",
    "\n",
    "def log_like(signal_strength):\n",
    "    if background_weight<0:\n",
    "        raise Exception('Negative background weight. Please update .npy file!')\n",
    "    if signal_weight<0:\n",
    "        raise Exception('Negative signal weight. Please update .npy file!')\n",
    "        \n",
    "    log_likelihood = 0\n",
    "    for i in range(len(bins)-1):\n",
    "        expected = background_weight*background_mass_binned[i]+signal_weight*signal_strength*signal_mass_binned[i]\n",
    "        observed = background_weight*background_mass_binned[i]+signal_weight*signal_mass_binned[i]\n",
    "        #print(expected)\n",
    "        log_likelihood = log_likelihood + observed*math.log(expected) - expected\n",
    "    return log_likelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural network utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [
     2,
     7,
     10,
     24
    ]
   },
   "outputs": [],
   "source": [
    "#FRANK# Returns a function that generates a padding layer\n",
    "#FRANK# x is the detector image, of following format:\n",
    "#FRANK# [index, image#(charged and neutral pt and multiplicity), 40, 40]\n",
    "def return_pad_me(padding):\n",
    "    def pad_me(x):\n",
    "        import tensorflow as tf # This solves 'TypeError: can't pickle _LazyLoader objects'\n",
    "        #FRANK# x[:,:,:y,:] slice x off from y at the given axis.\n",
    "        return(tf.concat((x,x[:,:,:padding,:]),2))\n",
    "    return(pad_me)\n",
    "\n",
    "def pad_out(padding,input_shape):\n",
    "    return input_shape\n",
    "\n",
    "class gen_call(Callback):\n",
    "    \n",
    "    def __init__(self, test_data):\n",
    "        self.x, self.y = test_data\n",
    "    \n",
    "    def on_train_begin(self,logs={}):\n",
    "        self.highest_SIC_train = []\n",
    "        self.highest_SIC_test = []\n",
    "        \n",
    "    def on_epoch_end(self,epoch,logs={}):\n",
    "        y_pred = self.model.predict(self.x)\n",
    "        self.highest_SIC_test.append(find_highest_SIC(self.y,y_pred))\n",
    "        print(str(self.highest_SIC_test[-1]) + \" is how good\")\n",
    "\n",
    "def show_outputs(output):\n",
    "    #Assumes the output is in shape like (32,41,36)\n",
    "    \n",
    "    fig = plt.figure(figsize=(8,6))\n",
    "    \n",
    "    for i in range(1,1+output.shape[0]):\n",
    "        fig.add_subplot(4,output.shape[0]/4,i)\n",
    "        plt.imshow(10*output[i-1,:,:])\n",
    "        plt.axis('off')\n",
    "    #plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FRANK# this method is the exact replica of find_highest_SIC() but operates on tensors.\n",
    "#FRANK# for some reason, pred has different format from expect. \n",
    "def highest_SIC_metric(y_true,y_pred):\n",
    "    import tensorflow as tf # This solves 'TypeError: can't pickle _LazyLoader objects'\n",
    "    print('highest_SIC_metric() is called')\n",
    "    y_true = tf.keras.backend.flatten(y_true) #FRANK# flattens to 1D\n",
    "    y_pred = tf.keras.backend.flatten(y_pred) #FRANK# flattens to 1D\n",
    "    \n",
    "    #stacked = tf.transpose(tf.stack((expect,predict)))\n",
    "    #to_sort = tf.reverse(sorted(stacked, key=lambda x: x[1]),0) #FRANK# sorted is wrong!!\n",
    "    total_sample = tf.cast(tf.size(y_pred), tf.float32)  # count total nums, then cast to float32 to avoid issue\n",
    "    total_signal = tf.cast(tf.reduce_sum(y_true), tf.float32)  # summing across all predicted (where sigs are 1's and bkgs are 0's) to get total num of signal. \n",
    "    total_background = tf.cast(tf.subtract(total_sample, total_signal), tf.float32)  # subtracting signal countss from total size to get background counts\n",
    "    \n",
    "    \n",
    "    # original mechanism:\n",
    "    # 1. sort by ML score\n",
    "    # 2. sum all actuals before an index\n",
    "    # 3. count all 0's before an index \n",
    "    \n",
    "    sorted_indices = tf.argsort(y_pred,axis=-1,direction='ASCENDING') # tf.argsort: Returns the indices of a tensor that give its sorted order along an axis.\n",
    "    sorted_sigs = tf.gather(y_pred,sorted_indices)\n",
    "    # return the indices of prediction in ascending order. By reading these indices, you can access corresponding expected y's.\n",
    "    ones = tf.fill(tf.shape(sorted_sigs), 1.0)\n",
    "    sorted_bkgs = tf.subtract(ones, sorted_sigs)\n",
    "    # make a sorted tensor where 1's are bkgs and 0's are sigs\n",
    "    \n",
    "    sig_cum_sums = tf.cast(tf.cumsum(sorted_sigs), tf.float32) # return the integrated signal number from 0 to each index\n",
    "    bkg_cum_sums = tf.cast(tf.cumsum(sorted_bkgs), tf.float32) # return the integrated bkg number from 0 to each index\n",
    "\n",
    "    sig_effs = tf.divide(sig_cum_sums, total_signal)\n",
    "    bkg_effs = tf.divide(bkg_cum_sums, total_background) #FRANK# total_background might be 0, causing bkg_effs=inf\n",
    "    effs = tf.divide(sig_effs, tf.sqrt(bkg_effs))\n",
    "        \n",
    "    return tf.reduce_max(effs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Event image hyperparameter tuning\n",
    "\n",
    "This section tunes the learning rate, epoch # and batch size of event image model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 40, 40)\n"
     ]
    }
   ],
   "source": [
    "# First define the global parameter input_shape - dimension of event images. \n",
    "# It is supposed to be a tuple.\n",
    "# This parameter is stored in every event image hdf5 files. \n",
    "f = h5py.File('vh-hj-event-image-hdf5/train.hdf5', 'r')\n",
    "input_shape = np.zeros(3, dtype='int32')\n",
    "dset = f['input_shape']\n",
    "dset.read_direct(input_shape)\n",
    "input_shape=tuple(input_shape)\n",
    "print(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "device CUDA:1 not supported by XLA service\n\twhile setting up XLA_GPU_JIT device number 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-abebd4e34a85>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Event image model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# --------------------------------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/device:XLA_GPU:0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mevent_image_cnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     event_image_cnn.add(Lambda(return_pad_me(4),\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36mdevice_v2\u001b[0;34m(device_name)\u001b[0m\n\u001b[1;32m   5175\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5176\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"tf.device does not support functions.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5177\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36mdevice\u001b[0;34m(device_name_or_function)\u001b[0m\n\u001b[1;32m   5130\u001b[0m           \u001b[0;34m\"tf.device does not support functions when eager execution \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5131\u001b[0m           \"is enabled.\")\n\u001b[0;32m-> 5132\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_name_or_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5133\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0mexecuting_eagerly_outside_functions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5134\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mtf_contextlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontextmanager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow_core/python/eager/context.py\u001b[0m in \u001b[0;36mdevice\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m   1687\u001b[0m     \u001b[0mContext\u001b[0m \u001b[0mmanager\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msetting\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1688\u001b[0m   \"\"\"\n\u001b[0;32m-> 1689\u001b[0;31m   \u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1690\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow_core/python/eager/context.py\u001b[0m in \u001b[0;36mensure_initialized\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1581\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1582\u001b[0m   \u001b[0;34m\"\"\"Initialize the context.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1583\u001b[0;31m   \u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow_core/python/eager/context.py\u001b[0m in \u001b[0;36mensure_initialized\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default_is_async\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mASYNC\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m           \u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTFE_ContextOptionsSetAsync\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 492\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_context_handle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTFE_NewContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    493\u001b[0m       \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m         \u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTFE_DeleteContextOptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: device CUDA:1 not supported by XLA service\n\twhile setting up XLA_GPU_JIT device number 1"
     ]
    }
   ],
   "source": [
    "# Create event image model automatically with tunable hyperparameter\n",
    "\n",
    "# --------------------------------------------------------------------------------------------\n",
    "# Event image model\n",
    "# --------------------------------------------------------------------------------------------\n",
    "\n",
    "event_image_cnn = Sequential()\n",
    "event_image_cnn.add(Lambda(return_pad_me(4),\n",
    "                 input_shape=input_shape))\n",
    "event_image_cnn.add(Conv2D(32, kernel_size=(5, 5), strides=(1, 1),\n",
    "                 activation='relu',\n",
    "                 data_format='channels_first'))\n",
    "event_image_cnn.add(Lambda(return_pad_me(1),\n",
    "                 input_shape=input_shape))\n",
    "event_image_cnn.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2),data_format='channels_first'))\n",
    "event_image_cnn.add(Lambda(return_pad_me(4),\n",
    "                 input_shape=input_shape))\n",
    "event_image_cnn.add(Conv2D(64, (5, 5), \n",
    "                 activation='relu',\n",
    "                 data_format='channels_first'))\n",
    "event_image_cnn.add(Lambda(return_pad_me(1),\n",
    "                 input_shape=input_shape))\n",
    "event_image_cnn.add(MaxPooling2D(pool_size=(2, 2),data_format='channels_first'))\n",
    "event_image_cnn.add(Flatten())\n",
    "event_image_cnn.add(Dense(300, activation='relu'))\n",
    "event_image_cnn.add(Dense(1, activation='sigmoid'))\n",
    "event_image_cnn.summary()\n",
    "\n",
    "#model_opt = keras.optimizers.Adadelta(lr=2.0, rho=0.95, epsilon=None, decay=0.0)\n",
    "model_opt = keras.optimizers.Adadelta(lr=0.08) # learning rate and decay rates are tunable\n",
    "\n",
    "event_image_cnn.compile(loss=keras.losses.binary_crossentropy,\n",
    "              optimizer=model_opt,\n",
    "              metrics=['accuracy', highest_SIC_metric])\n",
    "\n",
    "# Create training call for Tune using EVENT IMAGE\n",
    "# `config` should contain keys:\n",
    "#     'lr': learning rate\n",
    "#     'epoch': epoch number\n",
    "#     'batch': batch size\n",
    "# Change these two paths to specify which dataset to read from and where to store \n",
    "# their copies for each worker:\n",
    "\n",
    "source_hdf5_folder = '/home/ffu/higgs-classifier/analysis/vh-hj-event-image-hdf5' # Event images, including images \n",
    "                                                                            # generated from ggh (sig) and qcd (bkgd).\n",
    "temp_path = '/data0/users/frankfu/hbb-qcd-hdf5/'\n",
    "    \n",
    "x_train = HDF5Matrix(source_hdf5_folder+'/train.hdf5', 'x_train')\n",
    "y_train = HDF5Matrix(source_hdf5_folder+'/train.hdf5', 'y_train')\n",
    "x_test = HDF5Matrix(source_hdf5_folder+'/test.hdf5', 'x_test')\n",
    "y_test = HDF5Matrix(source_hdf5_folder+'/test.hdf5', 'y_test')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/device:XLA_GPU:3'):\n",
    "    event_image_cnn.fit(\n",
    "        x_train, \n",
    "        y_train, \n",
    "        validation_data=(\n",
    "            x_test, \n",
    "            y_test),\n",
    "        verbose=0, batch_size=300, epochs=2, \n",
    "        callbacks=[tensorboard_callback, gen_call((x_val,y_val))],\n",
    "        shuffle='batch' # TODO What error did this resolve?\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models (Example, please do not use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "device CUDA:1 not supported by XLA service\n\twhile setting up XLA_GPU_JIT device number 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-737869721270>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m jet_image_cnn.add(Conv2D(32, kernel_size=(5, 5), strides=(1, 1),\n\u001b[1;32m      6\u001b[0m                  \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m                 data_format='channels_first',input_shape=input_shape))\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;31m#jet_image_cnn.add(Dropout(0.5))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mjet_image_cnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMaxPooling2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpool_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'channels_first'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow_core/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    455\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/sequential.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    176\u001b[0m           \u001b[0;31m# and create the node connecting the current layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m           \u001b[0;31m# to the input layer we just created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m           \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m           \u001b[0mset_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    815\u001b[0m           \u001b[0;31m# Build layer if applicable (if the `build` method has been\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    816\u001b[0m           \u001b[0;31m# overridden).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 817\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    818\u001b[0m           \u001b[0mcast_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    819\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_maybe_build\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2139\u001b[0m         \u001b[0;31m# operations.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2140\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaybe_init_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2141\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2142\u001b[0m       \u001b[0;31m# We must set self.built since user defined build functions are not\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2143\u001b[0m       \u001b[0;31m# constrained to set self.built.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow_core/python/keras/layers/convolutional.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0mconstraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel_constraint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m         dtype=self.dtype)\n\u001b[0m\u001b[1;32m    166\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_bias\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m       self.bias = self.add_weight(\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36madd_weight\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, trainable, constraint, partitioner, use_resource, synchronization, aggregation, **kwargs)\u001b[0m\n\u001b[1;32m    520\u001b[0m         \u001b[0mcollections\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollections_arg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m         \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 522\u001b[0;31m         aggregation=aggregation)\n\u001b[0m\u001b[1;32m    523\u001b[0m     \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrack_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow_core/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_add_variable_with_custom_getter\u001b[0;34m(self, name, shape, dtype, initializer, getter, overwrite, **kwargs_for_getter)\u001b[0m\n\u001b[1;32m    742\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m         \u001b[0minitializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 744\u001b[0;31m         **kwargs_for_getter)\n\u001b[0m\u001b[1;32m    745\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m     \u001b[0;31m# If we set an initializer and the variable processed it, tracking will not\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer_utils.py\u001b[0m in \u001b[0;36mmake_variable\u001b[0;34m(name, shape, dtype, initializer, trainable, caching_device, validate_shape, constraint, use_resource, collections, synchronization, aggregation, partitioner)\u001b[0m\n\u001b[1;32m    137\u001b[0m       \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m       \u001b[0maggregation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m       shape=variable_shape if variable_shape else None)\n\u001b[0m\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow_core/python/ops/variables.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    256\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mVariableV1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_v1_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_v2_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow_core/python/ops/variables.py\u001b[0m in \u001b[0;36m_variable_v1_call\u001b[0;34m(cls, initial_value, trainable, collections, validate_shape, caching_device, name, variable_def, dtype, expected_shape, import_scope, constraint, use_resource, synchronization, aggregation, shape)\u001b[0m\n\u001b[1;32m    217\u001b[0m         \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m         \u001b[0maggregation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 219\u001b[0;31m         shape=shape)\n\u001b[0m\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m   def _variable_v2_call(cls,\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow_core/python/ops/variables.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m    195\u001b[0m                         shape=None):\n\u001b[1;32m    196\u001b[0m     \u001b[0;34m\"\"\"Call on Variable class. Useful to force the signature.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m     \u001b[0mprevious_getter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdefault_variable_creator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgetter\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creator_stack\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m       \u001b[0mprevious_getter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_make_getter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprevious_getter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow_core/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mdefault_variable_creator\u001b[0;34m(next_creator, **kwargs)\u001b[0m\n\u001b[1;32m   2505\u001b[0m         \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2506\u001b[0m         \u001b[0maggregation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2507\u001b[0;31m         shape=shape)\n\u001b[0m\u001b[1;32m   2508\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2509\u001b[0m     return variables.RefVariable(\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow_core/python/ops/variables.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    260\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_v2_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVariableMetaclass\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, initial_value, trainable, collections, validate_shape, caching_device, name, dtype, variable_def, import_scope, constraint, distribute_strategy, synchronization, aggregation, shape)\u001b[0m\n\u001b[1;32m   1404\u001b[0m           \u001b[0maggregation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1405\u001b[0m           \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1406\u001b[0;31m           distribute_strategy=distribute_strategy)\n\u001b[0m\u001b[1;32m   1407\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1408\u001b[0m   def _init_from_args(self,\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36m_init_from_args\u001b[0;34m(self, initial_value, trainable, collections, caching_device, name, dtype, constraint, synchronization, aggregation, distribute_strategy, shape)\u001b[0m\n\u001b[1;32m   1535\u001b[0m           \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Initializer\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_context_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1536\u001b[0m             initial_value = ops.convert_to_tensor(\n\u001b[0;32m-> 1537\u001b[0;31m                 \u001b[0minitial_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0minit_from_fn\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0minitial_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1538\u001b[0m                 name=\"initial_value\", dtype=dtype)\n\u001b[1;32m   1539\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer_utils.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    117\u001b[0m           (type(init_ops.Initializer), type(init_ops_v2.Initializer))):\n\u001b[1;32m    118\u001b[0m         \u001b[0minitializer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minitializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m       \u001b[0minit_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0minitializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m       \u001b[0mvariable_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_dtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0muse_resource\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow_core/python/ops/init_ops_v2.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, shape, dtype)\u001b[0m\n\u001b[1;32m    435\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m       \u001b[0mlimit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3.0\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 437\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_random_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_uniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow_core/python/ops/init_ops_v2.py\u001b[0m in \u001b[0;36mrandom_uniform\u001b[0;34m(self, shape, minval, maxval, dtype)\u001b[0m\n\u001b[1;32m    798\u001b[0m       \u001b[0mop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_uniform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m     return op(\n\u001b[0;32m--> 800\u001b[0;31m         shape=shape, minval=minval, maxval=maxval, dtype=dtype, seed=self.seed)\n\u001b[0m\u001b[1;32m    801\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    802\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mtruncated_normal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstddev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow_core/python/ops/random_ops.py\u001b[0m in \u001b[0;36mrandom_uniform\u001b[0;34m(shape, minval, maxval, dtype, seed, name)\u001b[0m\n\u001b[1;32m    235\u001b[0m     \u001b[0mmaxval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"random_uniform\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxval\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m     \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m     \u001b[0mminval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mminval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"min\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m     \u001b[0mmaxval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaxval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"max\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow_core/python/framework/tensor_util.py\u001b[0m in \u001b[0;36mshape_tensor\u001b[0;34m(shape)\u001b[0m\n\u001b[1;32m    962\u001b[0m       \u001b[0;31m# not convertible to Tensors becasue of mixed content.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m       \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_shape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdimension_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 964\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"shape\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    965\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    966\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, preferred_dtype, dtype_hint)\u001b[0m\n\u001b[1;32m   1182\u001b[0m   preferred_dtype = deprecation.deprecated_argument_lookup(\n\u001b[1;32m   1183\u001b[0m       \"dtype_hint\", dtype_hint, \"preferred_dtype\", preferred_dtype)\n\u001b[0;32m-> 1184\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconvert_to_tensor_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreferred_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor_v2\u001b[0;34m(value, dtype, dtype_hint, name)\u001b[0m\n\u001b[1;32m   1240\u001b[0m       \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m       \u001b[0mpreferred_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype_hint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1242\u001b[0;31m       as_ref=False)\n\u001b[0m\u001b[1;32m   1243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36minternal_convert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, ctx, accept_composite_tensors)\u001b[0m\n\u001b[1;32m   1294\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1295\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1296\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1298\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow_core/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_tensor_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    284\u001b[0m                                          as_ref=False):\n\u001b[1;32m    285\u001b[0m   \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow_core/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    225\u001b[0m   \"\"\"\n\u001b[1;32m    226\u001b[0m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0;32m--> 227\u001b[0;31m                         allow_broadcast=True)\n\u001b[0m\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow_core/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    233\u001b[0m   \u001b[0mctx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m     \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_to_eager_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow_core/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m   \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow_core/python/eager/context.py\u001b[0m in \u001b[0;36mensure_initialized\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default_is_async\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mASYNC\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m           \u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTFE_ContextOptionsSetAsync\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 492\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_context_handle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTFE_NewContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    493\u001b[0m       \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m         \u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTFE_DeleteContextOptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: device CUDA:1 not supported by XLA service\n\twhile setting up XLA_GPU_JIT device number 1"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------------------------------------\n",
    "# Jet image model\n",
    "# --------------------------------------------------------------------------------------------\n",
    "jet_image_cnn = Sequential()\n",
    "jet_image_cnn.add(Conv2D(32, kernel_size=(5, 5), strides=(1, 1),\n",
    "                 activation='relu',\n",
    "                data_format='channels_first',input_shape=input_shape))\n",
    "#jet_image_cnn.add(Dropout(0.5))\n",
    "jet_image_cnn.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2),data_format='channels_first'))\n",
    "jet_image_cnn.add(Conv2D(64, (5, 5), activation='relu',data_format='channels_first'))\n",
    "#jet_image_cnn.add(Dropout(0.5))\n",
    "jet_image_cnn.add(MaxPooling2D(pool_size=(2, 2),data_format='channels_first'))\n",
    "jet_image_cnn.add(Flatten())\n",
    "jet_image_cnn.add(Dense(1000, activation='relu'))\n",
    "#jet_image_cnn.add(Dropout(0.2))\n",
    "jet_image_cnn.add(Dense(1, activation='sigmoid'))\n",
    "#jet_image_cnn.summary()\n",
    "\n",
    "model_opt = keras.optimizers.Adadelta()\n",
    "\n",
    "jet_image_cnn.compile(loss=keras.losses.binary_crossentropy,\n",
    "              optimizer=model_opt,\n",
    "              metrics=['accuracy', 'highest_SIC_test'])\n",
    "\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------------------------------------\n",
    "# Combined model\n",
    "# --------------------------------------------------------------------------------------------\n",
    "#FRANK# input shape is calculated during splitting:\n",
    "#FRANK# splitData(background_image_list,signal_image_list)\n",
    "#FRANK# how is jet image taken?\n",
    "event_image_branch = Sequential()\n",
    "\n",
    "#FRANK# Lambda is from Keras.\n",
    "event_image_branch.add(Lambda(return_pad_me(5), #FRANK# tf.concat((x,x[:,:,:5,:]),2). Concatenate means pasting together.\n",
    "                            #FRANK# this layer slices off an edge of the tensor and paste it on the other side.\n",
    "                 input_shape=input_shape))\n",
    "event_image_branch.add(Conv2D(32, kernel_size=(5, 5), strides=(1, 1),\n",
    "                 activation='relu',\n",
    "                data_format='channels_first'))\n",
    "event_image_branch.add(Lambda(return_pad_me(2)))\n",
    "event_image_branch.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "event_image_branch.add(Lambda(return_pad_me(5),\n",
    "                 input_shape=input_shape))\n",
    "event_image_branch.add(Conv2D(64, (5, 5), activation='relu'))\n",
    "#event_image_branch.add(Dropout(0.5))\n",
    "event_image_branch.add(Lambda(return_pad_me(2)))\n",
    "event_image_branch.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "event_image_branch.add(Flatten())\n",
    "event_image_branch.add(Dense(300,activation='relu'))\n",
    "#event_image_branch.add(Dropout(0.5))\n",
    "\n",
    "jet_image_branch = Sequential()\n",
    "jet_image_branch.add(Conv2D(32, kernel_size=(5, 5), strides=(1, 1),\n",
    "                 activation='relu',\n",
    "                      kernel_initializer='random_uniform',input_shape=input_shape_r, data_format=\"channels_first\")) #FRANK# problemmatic. see debug note #1\n",
    "#jet_image_branch.add(Dropout(0.5))\n",
    "jet_image_branch.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "jet_image_branch.add(Conv2D(64, (5, 5), activation='relu'))\n",
    "#jet_image_branch.add(Dropout(0.5))\n",
    "jet_image_branch.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "jet_image_branch.add(Flatten())\n",
    "jet_image_branch.add(Dense(300, activation='relu'))\n",
    "#jet_image_branch.add(Dropout(0.5))\n",
    "\n",
    "\n",
    "\n",
    "#FRANK# Merge layer is no longer supported.  \n",
    "#combined_model = Sequential()\n",
    "#combined_model.add(Merge([event_image_branch, jet_image_branch], mode = 'concat'))\n",
    "#combined_model.add(Dense(1,activation='sigmoid'))\n",
    "\n",
    "#FRANK# these are not models, but tensors. Model.input or Model.output are tensor pointers I think.\n",
    "combined_model_tensor = Concatenate(axis=-1)([event_image_branch.output, jet_image_branch.output])   \n",
    "combined_model_tensor = Dense(1,activation='sigmoid')(combined_model_tensor)\n",
    "#FRANK# what you need to do is merging output of 300 and 300 into one.\n",
    "\n",
    "#combined_model.summary()\n",
    "combined_model = Model([event_image_branch.input,jet_image_branch.input], combined_model_tensor)\n",
    "combined_model.compile(loss=keras.losses.binary_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy', highest_SIC_metric])\n",
    "\n",
    "# Visualizing event image model\n",
    "plot_model(combined_model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Launch Tensorboard (run without \"%\" in terminal)\n",
    "%tensorboard --logdir tensorboard-logs/fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#FRANK# Sample training call testing metric\n",
    "epochs = 100\n",
    "print(y_train)\n",
    "with tf.device('/device:XLA_GPU:3'):\n",
    "    history_event_only = event_image_cnn.fit(\n",
    "        x_train, \n",
    "        y_train,\n",
    "        batch_size=1024,#batch_size,\n",
    "        epochs=epochs,\n",
    "        validation_data=(x_val,y_val),\n",
    "        verbose=1, shuffle=True, callbacks=[\n",
    "            EarlyStopping(monitor='highest_SIC_test', patience=2), \n",
    "            gen_call((x_val,y_val))])\n",
    "\n",
    "#FRANK# for event image SIC: predicting\n",
    "with tf.device('/device:XLA_GPU:3'):\n",
    "    y_pred_test = model.predict(x_test)\n",
    "    \n",
    "print(y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FRANK# testing metric\n",
    "print(np.array(y_pred.flatten()))\n",
    "print(np.array(y_test))\n",
    "print(highest_SIC_metric(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FRANK# training history plots\n",
    "def loss_history_plot(training_history):\n",
    "    print(training_history.history.keys())\n",
    "    plt.plot(training_history.history['loss'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print groomed mass histogram\n",
    "plt.rcParams['figure.figsize'] = [7.5,6]\n",
    "\n",
    "hist_bkg, bin_edges_bkg = np.histogram(background_mass_list, bins=21, range = (50, 197))\n",
    "bin_centers_bkg = (bin_edges_bkg[:-1] + bin_edges_bkg[1:]) / 2\n",
    "hist_sig, bin_edges_bkg = np.histogram(signal_mass_list, bins=21, range = (50, 197))\n",
    "\n",
    "\n",
    "if background_weight<0:\n",
    "    raise Exception('Negative background weight. Please update .npy file!')\n",
    "if signal_weight<0:\n",
    "    raise Exception('Negative signal weight. Please update .npy file!')\n",
    "plt.step(bin_centers_bkg, hist_bkg*background_weight, label='bkgd')\n",
    "plt.step(bin_centers_bkg, hist_sig*signal_weight, label='sig')\n",
    "plt.legend()\n",
    "plt.ylim(top=10000)\n",
    "plt.ylim(bottom=0)\n",
    "plt.xlim(right=197)  # adjust the right leaving left unchanged\n",
    "plt.xlim(left=50) \n",
    "plt.show()\n",
    "#log_like(1,background_mass_list=background_mass_list,signal_mass_list=signal_mass_list)\n",
    "\n",
    "# Calculating beta3\n",
    "background_beta3 = find_new_var_beta_3(background_reclustered,background_event_list_clustered,pt_cut = 1)\n",
    "signal_beta3 = find_new_var_beta_3(signal_reclustered,signal_event_list_clustered,pt_cut = 1)\n",
    "\n",
    "# Beta-3 histogram\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [5, 4]\n",
    "beta3_min = min([min(background_beta3),min(signal_beta3)])\n",
    "beta3_max = max([max(background_beta3),max(signal_beta3)])\n",
    "print('beta3 range is '+str((beta3_min, beta3_max)))\n",
    "plt.hist(background_beta3, label='bkgd', bins = 40, range = (beta3_min, 70), stacked=True, density=True,histtype ='step')\n",
    "plt.hist(signal_beta3, label='sig', bins = 40, range = (beta3_min, 70), stacked=True, density=True,histtype ='step')\n",
    "plt.xlabel(\"Beta-3\")\n",
    "plt.ylabel(\"Normalized Shape\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.hist(background_mass_list, label='bkgd', bins = 21, range = (50, 197), stacked=True, density=True,histtype ='step')\n",
    "plt.hist(signal_mass_list, label='sig', bins = 21, range = (50, 197), stacked=True, density=True,histtype ='step')\n",
    "plt.xlabel(\"Trimmed Mass\")\n",
    "plt.ylabel(\"Normalized Shape\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Beta-3 plots\n",
    "plot_simple_ROC_SIC(signal_beta3, background_beta3, step = 0.001):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the predicted results into sample and background using known answers.\n",
    "# Here we assume all backgrounds are put before signals in all datasets. \n",
    "#TODO# Check before use!\n",
    "\n",
    "def split_sig_bkgd(predicted, expected)\n",
    "    split_location = int(np.argwhere(expected==1.)[0])\n",
    "    #FRANK# signal predictions with event image model\n",
    "    sig = predicted[split_location:]\n",
    "    bkgd = predicted[:split_location]\n",
    "\n",
    "    return sig, bkgd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FRANK# calculating true positive rates and false positive rates. \n",
    "#FRANK# TPR = TP/P\n",
    "#FRANK# FPR = FP/N\n",
    "#FRANK# note that bkgds have lower beta in general, so the cut should be \n",
    "#FRANK# beta3 > threshold.\n",
    "#FRANK# 'where' usage referred from \n",
    "#FRANK# https://stackoverflow.com/questions/12995937/count-all-values-in-a-matrix-greater-than-a-value\n",
    "\n",
    "def simple_ROC(sig, bkgd, step = 1):\n",
    "    thres_min = min([min(sig),min(bkgd)])\n",
    "    thres_max = max([max(sig),max(bkgd)])\n",
    "    search_range=(thres_min, thres_max)\n",
    "    sig_count = len(sig)\n",
    "    bkgd_count = len(bkgd)\n",
    "    sig_rates = []\n",
    "    bkgd_rates = []\n",
    "    thres_list = np.arange(search_range[0], search_range[1], step)\n",
    "    for thres in thres_list:\n",
    "        sig_selected = np.greater(sig, thres)\n",
    "        bkgd_selected = np.greater(bkgd, thres)\n",
    "        sig_rates.append(np.sum(sig_selected)/sig_count)\n",
    "        bkgd_rates.append(np.sum(bkgd_selected)/bkgd_count)\n",
    "    return sig_rates, bkgd_rates, thres_list\n",
    "\n",
    "def plot_simple_ROC_SIC(sig, bkgd, step = 0.001):\n",
    "    \n",
    "    # Calculate simple ROC curve\n",
    "    sig_rates, bkgd_rates, thres_list = simple_ROC(sig, bkgd, step)\n",
    "    \n",
    "\n",
    "    # Plotting ROC\n",
    "    plt.rcParams['figure.figsize'] = [6, 6]\n",
    "    plt.plot(sig_rates, bkgd_rates,label='bkgd',linewidth=1)\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"signal rate\")\n",
    "    plt.ylabel(\"background rate\")\n",
    "    plt.show()\n",
    "\n",
    "    # Plotting SIC (ε/√ε_b) \n",
    "    event_significances = sig_rates/np.sqrt(bkgd_rates)\n",
    "    plt.rcParams['figure.figsize'] = [5, 4]\n",
    "    plt.plot(sig_rates,event_significances,label='beta3',linewidth=1)\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"signal rate\")\n",
    "    plt.ylabel(\"significance improvement\")\n",
    "    plt.ylim(top=2.5)\n",
    "    plt.ylim(bottom=1)\n",
    "    plt.xlim(right=1)  # adjust the right leaving left unchanged\n",
    "    plt.xlim(left=0.1) \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here evaluate ML performance by e.g.\n",
    "#r_combine_y,r_combine_x = generate_real_SIC(y_test,new_model_combine.predict([x_test,x_test_r]),mass_test,quality=1)\n",
    "\n",
    "r_full_y,r_full_x = generateSIC(y_test,predicted, quality=100)\n",
    "#r_fine_y,r_fine_x = generate_real_SIC(y_test,model_fine.predict(x_test_r),mass_test,quality=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "plt.title(\"Binned Likelihood Significance Improvements for various Architectures\")\n",
    "#plt.plot(r_combine_x,r_combine_y,color=\"red\",label=\"Full CNN Architecture\",linewidth=1)\n",
    "plt.plot(r_full_x,r_full_y,color=\"red\",alpha=0.6,label=\"Event image only\",linewidth=1,linestyle=\"dashed\")\n",
    "#plt.plot(r_fine_x,r_fine_y,color=\"red\",alpha=0.6,label=\"Jet image only\",linewidth=1,linestyle=\"dotted\")\n",
    "#plt.plot(beta_x,beta_y,color=\"blue\",alpha=0.6,label=r\"$\\beta_3$\",linewidth=1)#,linestyle=\"dashed\")\n",
    "#plt.plot(three_x,three_y,color=\"blue\",alpha=0.6,label=r\"$Rb_2$\",linewidth=1,linestyle=\"dotted\")\n",
    "#plt.plot(x_02,y_02,color=\"gray\",label=\"Jet image, no neutral layer\",linewidth=1)\n",
    "#plt.plot(vars_y,vars_x,color=\"blue\",label=r\"$\\beta_3 + Rb_2$\",linewidth=1)\n",
    "plt.xlim(0.1,1)\n",
    "plt.ylim(1,2.3)\n",
    "plt.legend()\n",
    "plt.xlabel(\"Signal Efficiency\")\n",
    "plt.ylabel(\"Significance Improvement\")\n",
    "plt.savefig('all_SIC.eps')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9,7))\n",
    "plt.title(\"Binned Likelihood Significance Improvements for various Architectures\")\n",
    "#plt.plot(r_combine_x,r_combine_y,color=\"red\",label=\"Full CNN Architecture\",linewidth=1)\n",
    "#plt.plot(r_full_x,r_full_y,color=\"red\",alpha=0.6,label=\"Event image only\",linewidth=1,linestyle=\"dashed\")\n",
    "#plt.plot(r_fine_x,r_fine_y,color=\"red\",alpha=0.6,label=\"Jet image only\",linewidth=1,linestyle=\"dotted\")\n",
    "#FRANK# event image SIC\n",
    "plt.plot(r_full_x,r_full_y,color=\"red\",alpha=0.6,label=\"Event image only\",linewidth=1,linestyle=\"dashed\")\n",
    "plt.plot(sig_rates,significances,label='Beta3',linewidth=1)\n",
    "#FRANK# beta-3 SIC\n",
    "#plt.plot(beta_x,beta_y,color=\"blue\",alpha=0.6,label=r\"$\\beta_3$\",linewidth=1)#,linestyle=\"dashed\")\n",
    "#plt.plot(three_x,three_y,color=\"blue\",alpha=0.6,label=r\"$Rb_2$\",linewidth=1,linestyle=\"dotted\")\n",
    "#plt.plot(x_02,y_02,color=\"gray\",label=\"Jet image, no neutral layer\",linewidth=1)\n",
    "#plt.plot(vars_y,vars_x,color=\"blue\",label=r\"$\\beta_3 + Rb_2$\",linewidth=1)\n",
    "plt.xlim(0.1,1)\n",
    "plt.ylim(1,2.5)\n",
    "plt.legend()\n",
    "plt.xlabel(\"Signal Efficiency\")\n",
    "plt.ylabel(\"Significance Improvement\")\n",
    "plt.savefig('all_SIC.eps')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 Keras",
   "language": "python",
   "name": "python_3_keras"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
