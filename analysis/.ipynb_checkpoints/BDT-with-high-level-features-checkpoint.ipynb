{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import save_and_load\n",
    "import importlib\n",
    "import substructure\n",
    "import numpy as np\n",
    "import csv_decoder\n",
    "from matplotlib import pyplot\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading VH and hj\n",
    "vh_event_list, hj_event_list, vh_mass_list, hj_mass_list,\\\n",
    "        vh_higgs, hj_higgs, vh_weight, hj_weight, vh_image_list, hj_image_list,\\\n",
    "        vh_recluster_images, hj_recluster_images = save_and_load.load_binary('vh-hj', name_1='vh', name_2='hj')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster 0.8 jets\n",
    "importlib.reload(csv_decoder)\n",
    "vh_clustered = csv_decoder.cluster_event(vh_event_list)\n",
    "hj_clustered = csv_decoder.cluster_event(hj_event_list)\n",
    "vh_reclustered, vh_non_higgs_jets = csv_decoder.recluster_event(vh_clustered, vh_higgs)\n",
    "hj_reclustered, hj_non_higgs_jets = csv_decoder.recluster_event(hj_clustered, hj_higgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-f4302f54b35f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mvh_non_higgs_jets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mvh_non_higgs_jets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meta\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         substructure.find_new_var_N_2(vh_reclustered,vh_clustered)))\n\u001b[0m\u001b[1;32m     34\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"working\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/higgs-classifier/analysis/substructure.py\u001b[0m in \u001b[0;36mfind_new_var_N_2\u001b[0;34m(reclustered, clustered)\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjcon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjcon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m                 \u001b[0mv_1e2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mv_1e2\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0mjcon\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpt\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mjcon\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpt\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjcon\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mjcon\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp_total\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m         \u001b[0;31m#v_1e2 = np.sum([[(con1.pt/p_total)*(con2.pt/p_total)*R(con1,con2) for con1 in jcon] for con2 in jcon])/2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0mv_2e3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/higgs-classifier/analysis/substructure.py\u001b[0m in \u001b[0;36mR\u001b[0;34m(con1, con2)\u001b[0m\n\u001b[1;32m    582\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcon1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcon2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 584\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcon1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meta\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mcon2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mdphi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcon1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mphi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcon2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mphi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    586\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mR_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcon1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcon2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Extracting data for VH\n",
    "importlib.reload(substructure)\n",
    "vh_higgs_pt = []\n",
    "vh_higgs_eta = []\n",
    "vh_non_higgs_leading_m = []\n",
    "vh_non_higgs_leading_pt = []\n",
    "vh_non_higgs_leading_eta = []\n",
    "vh_N2 = substructure.find_new_var_N_2(vh_reclustered,vh_clustered)\n",
    "\n",
    "# High-level features used for training. The Features included are:\n",
    "# [\n",
    "# 0: higgs mass\n",
    "# 1: higgs pt\n",
    "# 2: higgs eta\n",
    "# 3: non-higgs mass\n",
    "# 4: non-higgs pt\n",
    "# 5: non-higgs eta\n",
    "# 6: non-higgs n2\n",
    "vh_x = []\n",
    "for i in range(len(vh_event_list)):\n",
    "    vh_higgs_pt.append(vh_higgs[i][0])\n",
    "    vh_higgs_eta.append(vh_higgs[i][1])\n",
    "    vh_non_higgs_leading_m.append(vh_non_higgs_jets[i].mass)\n",
    "    vh_non_higgs_leading_pt.append(vh_non_higgs_jets[i].pt)\n",
    "    vh_non_higgs_leading_eta.append(vh_non_higgs_jets[i].eta)\n",
    "    \n",
    "    vh_x.append((\n",
    "        vh_mass_list[i],\n",
    "        vh_higgs[i][0],\n",
    "        vh_higgs[i][1],\n",
    "        vh_non_higgs_jets[i].mass,\n",
    "        vh_non_higgs_jets[i].pt,\n",
    "        vh_non_higgs_jets[i].eta,\n",
    "        vh_N2[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting data for hj\n",
    "hj_higgs_pt = []\n",
    "hj_higgs_eta = []\n",
    "hj_non_higgs_leading_m = []\n",
    "hj_non_higgs_leading_pt = []\n",
    "hj_non_higgs_leading_eta = []\n",
    "\n",
    "# High-level features used for training. The Features included are:\n",
    "# [\n",
    "# 0: higgs mass\n",
    "# 1: higgs pt\n",
    "# 2: higgs eta\n",
    "# 3: non-higgs mass\n",
    "# 4: non-higgs pt\n",
    "# 5: non-higgs eta\n",
    "# 6: non-higgs n2\n",
    "hj_train = []\n",
    "for i in range(len(hj_event_list)):\n",
    "    hj_higgs_pt.append(hj_higgs[i][0])\n",
    "    hj_higgs_eta.append(hj_higgs[i][1])\n",
    "    hj_non_higgs_leading_m.append(hj_non_higgs_jets[i].mass)\n",
    "    hj_non_higgs_leading_pt.append(hj_non_higgs_jets[i].pt)\n",
    "    hj_non_higgs_leading_eta.append(hj_non_higgs_jets[i].eta)\n",
    "    \n",
    "    hj_train.append((\n",
    "        hj_mass_list[i],\n",
    "        hj_higgs[i][0],\n",
    "        hj_higgs[i][1],\n",
    "        hj_non_higgs_jets[i].mass,\n",
    "        hj_non_higgs_jets[i].pt,\n",
    "        hj_non_higgs_jets[i].eta,\n",
    "        substructure.find_new_var_N_2(hj_reclustered,hj_clustered)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A simple method splitting binary training data\n",
    "# the first group of data (background) is automatically given classification 0,\n",
    "# and the decond group (signal) is automatically given classification 1\n",
    "# the parameter rsplit specifies 2 cutting points\n",
    "def split_data(background_image_list, signal_image_list, rsplit = np.array([0.5,0.75])):        \n",
    "    b_split = np.split(background_image_list,(len(background_image_list)*rsplit).astype(int))\n",
    "    s_split = np.split(signal_image_list,(len(signal_image_list)*rsplit).astype(int))\n",
    "    \n",
    "    x_train = np.concatenate((b_split[0],s_split[0]))\n",
    "    y_train = np.array(np.concatenate((np.zeros(len(b_split[0])),np.ones(len(s_split[0])))))\n",
    "    \n",
    "    x_val = np.concatenate((b_split[1],s_split[1]))\n",
    "    y_val = np.array(np.concatenate((np.zeros(len(b_split[1])),np.ones(len(s_split[1])))))\n",
    "    \n",
    "    x_test = np.concatenate((b_split[2],s_split[2]))\n",
    "    y_test = np.array(np.concatenate((np.zeros(len(b_split[2])),np.ones(len(s_split[2])))))\n",
    "    return(input_shape,\n",
    "           x_train,y_train,mass_train,\n",
    "           x_val,y_val,mass_val,\n",
    "           x_test,y_test,mass_test,\n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating classifier\n",
    "bdt = AdaBoostClassifier(DecisionTreeClassifier(max_depth=5),\n",
    "                         algorithm=\"SAMME.R\",\n",
    "                         n_estimators=200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 Keras",
   "language": "python",
   "name": "python_3_keras"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
