{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# File processor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook processes .csv files produced by the showering program, performs fast detector simulation to generate detector/jet images, and saves to faster np.save format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading CSV\n",
    "\n",
    "# This function reads off the original CSV format: \n",
    "# pt, eta, phi, m, id, isCharged \\n\n",
    "# pt, eta, phi, m, id, isCharged \\n\n",
    "# ... (of all particles in one event)\n",
    "# trimmed mass of identified jet \\n\n",
    "# \\n\n",
    "# and produces a event_list\n",
    "def return_event_list(fileName,max_Read = float(\"inf\"),weighted=0,pt_cut=1):\n",
    "    \n",
    "    printed = 0\n",
    "    \n",
    "    event_list = [];mass_list = [];weight_list = [];\n",
    "    tmp_events = open(fileName).read().split(\"\\n\\n\")[:-1]\n",
    "    print(len(tmp_events))\n",
    "    for x in tmp_events:\n",
    "        try:\n",
    "            if len(event_list) == max_Read: #FRANK# limit event size. If violated, interrupt the entire method\n",
    "                return(event_list,mass_list)\n",
    "            if weighted == 0:\n",
    "                                \n",
    "                #FRANK# rfind finds the last occurance\n",
    "                #FRANK# [a:b] extract everything b/w a and bth elem, including ath and excluding bth\n",
    "                #FRANK# why isn't the cut applied to weight and mass list? #ISSUE#\n",
    "                \n",
    "                mass_list.append(float(x[x.rfind(\"\\n\")+1:-1]))\n",
    "                to_cut = np.array(np.genfromtxt(x[:x.rfind(\"\\n\")].splitlines(), delimiter=\",\"))\n",
    "                event_list.append(to_cut[[x[0] > pt_cut for x in to_cut]])\n",
    "            else:\n",
    "                weight_list.append(float(x[x.rfind(\"\\n\")+1:]))\n",
    "                mass_list.append(float(x[x.rfind(\"\\n\",0,x.rfind(\"\\n\")-1)+1:x.rfind(\"\\n\")+1]))\n",
    "                to_cut = np.genfromtxt(x[:x.rfind(\"\\n\")].splitlines(),delimiter=\",\")\n",
    "                event_list.append(to_cut[[x[0] > pt_cut for x in to_cut]])\n",
    "        except:\n",
    "            print('We failed to turn your CSV into an np array. Make sure you have the correct format. ')\n",
    "            print( sys.exc_info()[0])\n",
    "            return\n",
    "    if weighted == 0:\n",
    "        #print(mass_list[0])\n",
    "        return(event_list,mass_list)\n",
    "    else:\n",
    "        return(event_list,mass_list,weight_list)\n",
    "\n",
    "#FRANK# Converting event_list to event image\n",
    "def return_image_list(event_list):\n",
    "    image_list = []\n",
    "    image_0 = np.zeros((width,height)) #Charged pt #FRANK# I think it's labeled wrong here. Would it matter?\n",
    "    image_1 = np.zeros((width,height)) #Neutral pt\n",
    "    image_2 = np.zeros((width,height)) #Charged multiplicity\n",
    "    \n",
    "    #FRANK# pt, eta, phi, m, id, isCharged \\n\n",
    "    #FRANK# 0   1    2    3  4   5\n",
    "    for z in range(len(event_list)):\n",
    "        image_0 = np.zeros((width,height));image_1 = np.zeros((width,height));image_2 = np.zeros((width,height))\n",
    "        for x in range(len(event_list[z])):\n",
    "            phi_index = math.floor(width*event_list[z][x,2]//(2*math.pi)+width//2)\n",
    "            eta_index = math.floor(height*event_list[z][x,1]//10+height/2) #FRANK# // is integer divide\n",
    "            eta_index = min(eta_index,height-1)\n",
    "            eta_index = max(0,eta_index)\n",
    "            phi_index = int(phi_index);eta_index = int(eta_index)\n",
    "            if (event_list[z][x,5] == 0):  #FRANK# neutral\n",
    "                image_0[phi_index,eta_index] = image_0[phi_index,eta_index] + event_list[z][x,0]\n",
    "            elif (event_list[z][x,5] == 1):  #FRANK# charged\n",
    "                image_1[phi_index,eta_index] = image_1[phi_index,eta_index] + event_list[z][x,0]\n",
    "                image_2[phi_index,eta_index] = image_2[phi_index,eta_index] + 1\n",
    "        image_0 = np.divide(image_0,np.sum(image_0))\n",
    "        image_1 = np.divide(image_1,np.sum(image_1))\n",
    "        image_2 = np.divide(image_2,np.sum(image_2))\n",
    "        image_list.append(np.array([image_0,image_1,image_2]))\n",
    "    return(image_list)\n",
    "\n",
    "# This method loads event files to produce:\n",
    "# event_list, mass_list, image_list, files_Read and weight_list\n",
    "def load_events(event_type,debug = 0, max_Read = float(\"inf\"), max_Files = float(\"inf\"), weighted=0, \\\n",
    "                path = \"/data1/users/jzlin/NLO/\", contains = \"philback\", pt_cut = 0):\n",
    "    print(\"Loading events for \" + event_type)\n",
    "    reading_event_list,reading_mass_list = [],[]\n",
    "    reading_image_list = []\n",
    "    reading_weight_list = []\n",
    "    files_Read = 0\n",
    "    print('list of files is'+ str(os.listdir(path)))\n",
    "    for i in os.listdir(path):\n",
    "        print('test: i is: '+ str(i))\n",
    "        print('total path is: '+os.path.join(path,i))\n",
    "        \n",
    "        if (files_Read == max_Files):\n",
    "            break\n",
    "        if len(reading_event_list) >= max_Read:\n",
    "            return(reading_event_list,reading_mass_list,reading_image_list,files_Read)\n",
    "        if 'swp' in i:\n",
    "            continue\n",
    "        if os.path.isfile(os.path.join(path,i)) and (event_type+contains) in i:\n",
    "            if debug==1:\n",
    "                print(i)\n",
    "                print(os.path.join(path,i))\n",
    "            if weighted==0:\n",
    "                print(i)\n",
    "                temp_event_list,temp_mass_list = return_event_list(os.path.join(path,i),pt_cut=pt_cut)\n",
    "            else:\n",
    "                temp_event_list,temp_mass_list,temp_weight_list = return_event_list(os.path.join(path,i),\n",
    "                                                                                    weighted=1,pt_cut=pt_cut)\n",
    "                reading_weight_list = reading_weight_list = temp_weight_list\n",
    "            temp_image_list = return_image_list(temp_event_list)\n",
    "            if (len(temp_image_list) != len(temp_mass_list)):\n",
    "                print(\"Something has gone wrong when reading the file\")\n",
    "                print(os.path.join(path,i))\n",
    "            reading_event_list = reading_event_list + temp_event_list\n",
    "            reading_mass_list = reading_mass_list + temp_mass_list\n",
    "            reading_image_list = reading_image_list + temp_image_list\n",
    "            files_Read = files_Read + 1\n",
    "            print(\"Read \" + str(files_Read) + \" number of files\\r\")\n",
    "    if weighted==0:\n",
    "        return(reading_event_list,reading_mass_list,reading_image_list,files_Read)\n",
    "    else:\n",
    "        return(reading_event_list,reading_mass_list,reading_image_list,files_Read,reading_weight_list)\n",
    "\n",
    "# This is not used. \n",
    "def return_fine_image_list(event_list, event_list_clustered, granularity, which_jet = 0):\n",
    "    image_list = []\n",
    "    image_0 = np.zeros((width,height)) #Charged pt\n",
    "    image_1 = np.zeros((width,height)) #Neutral pt\n",
    "    image_2 = np.zeros((width,height)) #Charged multiplicity\n",
    "\n",
    "    for z in range(len(event_list)):\n",
    "        image_0 = np.zeros((width,height))\n",
    "        image_1 = np.zeros((width,height))\n",
    "        image_2 = np.zeros((width,height))\n",
    "        for x in range(len(event_list[z])):\n",
    "            \n",
    "            try:\n",
    "                phi_index = (event_list[z][x,2]-event_list_clustered[z][which_jet].phi)\n",
    "            except:\n",
    "                print(z)\n",
    "            #At this point, phi_index is just delta_phi, which could be anywhere from -2pi to 2pi\n",
    "            if (phi_index % (2*math.pi) >= (width//2)*granularity) and (phi_index % (2*math.pi) <= 2*math.pi-(width//2)*granularity):\n",
    "                continue\n",
    "                #This gets rid of the delta phi's that are far away from the jet\n",
    "            phi_index = phi_index % (2*math.pi)\n",
    "            if phi_index > math.pi:\n",
    "                 phi_index = phi_index - 2*math.pi   \n",
    "            phi_index = int(math.floor(phi_index/granularity)) #should be good now\n",
    "            if (phi_index > (width//2)) or (phi_index < -(width//2)):\n",
    "                print(phi_index)\n",
    "            phi_index = phi_index + (width//2)\n",
    "            \n",
    "\n",
    "            eta_index = int(math.floor((event_list[z][x,1]-event_list_clustered[z][which_jet].eta)/granularity) + height//2)\n",
    "            if eta_index >= height:\n",
    "                continue\n",
    "            if eta_index < 0:\n",
    "                continue\n",
    "            \n",
    "            #finally, lets fill\n",
    "            if (event_list[z][x,5] == 0):\n",
    "                image_0[phi_index,eta_index] = image_0[phi_index,eta_index] + event_list[z][x,0]\n",
    "            elif (event_list[z][x,5] == 1):\n",
    "                image_1[phi_index,eta_index] = image_1[phi_index,eta_index] + event_list[z][x,0]\n",
    "                image_2[phi_index,eta_index] = image_2[phi_index,eta_index] + 1\n",
    "\n",
    "        #Now, lets go through and normalise to 255\n",
    "        image_0 = np.divide(image_0,np.sum(image_0))\n",
    "        image_1 = np.divide(image_1,np.sum(image_1))\n",
    "        image_2 = np.divide(image_2,np.sum(image_2))\n",
    "        image_list.append(np.array([image_0,image_1,image_2]))\n",
    "    return(image_list)\n",
    "\n",
    "def cluster_event(event_list):\n",
    "    event_list_clustered = []\n",
    "    for x in range(len(event_list)):\n",
    "        to_Cluster = np.array([event_list[x][:,0],event_list[x][:,1],event_list[x][:,2],event_list[x][:,3]])\n",
    "        to_Cluster = np.swapaxes(to_Cluster,0,1)\n",
    "        to_Cluster = np.core.records.fromarrays(to_Cluster.transpose(), \n",
    "                                             names='pT, eta, phi, mass',\n",
    "                                             formats = 'f8, f8, f8,f8')\n",
    "        sequence_Cluster = cluster(to_Cluster, R = 0.8,p = -1)\n",
    "        jets_Cluster = sequence_Cluster.inclusive_jets()\n",
    "        event_list_clustered.append(jets_Cluster)\n",
    "    return(event_list_clustered)\n",
    "\n",
    "def recluster_event(cluster_list):\n",
    "    reclustered_list= []\n",
    "    for i in range(len(cluster_list)):\n",
    "        sequence_Cluster = cluster((cluster_list[i][0]), R=0.2,p=-1)\n",
    "        jets_Cluster = sequence_Cluster.inclusive_jets()\n",
    "        reclustered_list.append(jets_Cluster)\n",
    "    return(reclustered_list)\n",
    "\n",
    "def return_fine_image_list_reclustered(event_list, event_list_clustered, radius, which_jet = 0,verbose = False):\n",
    "    image_list = []\n",
    "    image_0 = np.zeros((width,height)) #Neutral pt\n",
    "    image_1 = np.zeros((width,height)) #Charged pt\n",
    "    image_2 = np.zeros((width,height)) #Charged multiplicity\n",
    "    \n",
    "    no_two = 0\n",
    "\n",
    "    for z in range(len(event_list)):\n",
    "        image_0 = np.zeros((width,height))\n",
    "        image_1 = np.zeros((width,height))\n",
    "        image_2 = np.zeros((width,height))\n",
    "        \n",
    "        if (len(event_list_clustered[z]) > 1):\n",
    "            #First, let's find the direction of the second-hardest jet relative to the first-hardest subjet\n",
    "            phi_dir = -(dphi(event_list_clustered[z][1].phi,event_list_clustered[z][0].phi))\n",
    "            eta_dir = -(event_list_clustered[z][1].eta - event_list_clustered[z][0].eta)\n",
    "            #Norm difference:\n",
    "            norm_dir = np.linalg.norm([phi_dir,eta_dir])\n",
    "            #This is now the y-hat direction. so we can actually find the unit vector:\n",
    "            y_hat = np.divide([phi_dir,eta_dir],np.linalg.norm([phi_dir,eta_dir]))\n",
    "            #and we can find the x_hat direction as well\n",
    "            x_hat = np.array([y_hat[1],-y_hat[0]]) \n",
    "        else:\n",
    "            no_two = no_two + 1\n",
    "            #continue\n",
    "            \n",
    "        if verbose==True:\n",
    "            print(x_hat,y_hat,norm_dir)\n",
    "            \n",
    "        \n",
    "        for x in range(len(event_list[z])):\n",
    "            if (len(event_list_clustered[z]) == 1):\n",
    "                #In the case that the reclustering only found one hard jet (that seems kind of bad, but hey)\n",
    "                #no_two = no_two+1\n",
    "                new_coord = [dphi(event_list[z][x,2],event_list_clustered[z][0].phi),event_list[z][x,1]-event_list_clustered[z][0].eta]\n",
    "                indxs = [math.floor(width*new_coord[0]/(radius*1.5))+width//2,math.floor(height*(new_coord[1])/(radius*1.5))+height//2]\n",
    "            else:\n",
    "                #Now, we want to express an incoming particle in this new basis:\n",
    "                part_coord = [dphi(event_list[z][x,2],event_list_clustered[z][0].phi),event_list[z][x,1]-event_list_clustered[z][0].eta]\n",
    "                new_coord = np.dot(np.array([x_hat,y_hat]),part_coord)\n",
    "                #Now, we want to cast these new coordinates into our array\n",
    "                indxs = [math.floor(width*new_coord[0]/(radius*1.5))+width//2,math.floor(height*(new_coord[1]+norm_dir/1.5)/(radius*1.5))+height//2]\n",
    "                \n",
    "            if indxs[0] >= width or indxs[1] >= height or indxs[0] <= 0 or indxs[1] <= 0:\n",
    "                continue\n",
    "            phi_index = int(indxs[0]); eta_index = int(indxs[1])\n",
    "            #finally, lets fill\n",
    "            if (event_list[z][x,5] == 0):\n",
    "                image_0[phi_index,eta_index] = image_0[phi_index,eta_index] + event_list[z][x,0]\n",
    "            elif (event_list[z][x,5] == 1):\n",
    "                image_1[phi_index,eta_index] = image_1[phi_index,eta_index] + event_list[z][x,0]\n",
    "                image_2[phi_index,eta_index] = image_2[phi_index,eta_index] + 1\n",
    "\n",
    "        #Now, lets go through and normalise to 255\n",
    "        if (np.sum(image_0) == 0 or np.sum(image_1) == 0 or np.sum(image_2) == 0):\n",
    "            image_list.append(np.array([image_0,image_1,image_2]))\n",
    "            continue\n",
    "        image_0 = np.divide(image_0,np.sum(image_0))\n",
    "        image_1 = np.divide(image_1,np.sum(image_1))\n",
    "        image_2 = np.divide(image_2,np.sum(image_2))\n",
    "        image_list.append(np.array([image_0,image_1,image_2]))\n",
    "    print(\"no two \" + str(no_two))\n",
    "    return(image_list)\n",
    "\n",
    "# Correct phi range\n",
    "def fix_phi(phi):\n",
    "    while phi > math.pi:\n",
    "        phi = phi - 2*math.pi\n",
    "    while phi < -math.pi:\n",
    "        phi = phi + 2*math.pi\n",
    "    return phi\n",
    "\n",
    "# Returns the difference in phi between phi, and phi_center\n",
    "# as a float between (-PI, PI)\n",
    "def dphi(phi,phi_c):\n",
    "    \n",
    "    dphi_temp = phi - phi_c\n",
    "    while dphi_temp > np.pi:\n",
    "        dphi_temp = dphi_temp - 2*np.pi\n",
    "    while dphi_temp < -np.pi:\n",
    "        dphi_temp = dphi_temp + 2*np.pi\n",
    "    return (dphi_temp)\n",
    "\n",
    "# Rapidity\n",
    "def y(p):\n",
    "    return ((1/2)*math.log((p.e+p.pz)/(p.e-p.pz)))\n",
    "\n",
    "def R(con1,con2):\n",
    "    return (((con1.eta-con2.eta)**2+dphi(con1.phi,con2.phi)**2)**(1/2))\n",
    "\n",
    "def R_y(con1,con2):\n",
    "    return (((y(con1)-y(con2))**2+dphi(con1.phi,con2.phi)**2)**(1/2))\n",
    "\n",
    "def N_2(jcon):\n",
    "    #Takes jcon, jet constituents\n",
    "    p_x_total = np.sum([con.px for con in jcon])\n",
    "    p_y_total = np.sum([con.py for con in jcon])\n",
    "    p_total = (p_x_total**2+p_y_total**2)**(1/2)\n",
    "    \n",
    "    v_1e2 = 0\n",
    "    for i in range(len(jcon)):\n",
    "        for j in range(i+1,len(jcon)):\n",
    "            v_1e2 = v_1e2+ jcon[i].pt*jcon[j].pt*R(jcon[i],jcon[j])/(p_total**2)\n",
    "    v_2e3 = 0\n",
    "    for i in range(len(jcon)):\n",
    "        for j in range(i+1,len(jcon)):\n",
    "            for k in range(j+1,len(jcon)):\n",
    "                v_2e3 = v_2e3 + jcon[i].pt*jcon[j].pt*jcon[j].pt*min(R(jcon[i],jcon[j])*R(jcon[i],jcon[k]),\n",
    "                                                                     R(jcon[j],jcon[k])*R(jcon[i],jcon[j]),\n",
    "                                                        R(jcon[i],jcon[k])*R(jcon[j],jcon[k]))/(p_total**3)\n",
    "    return v_2e3/(v_1e2**2)\n",
    "\n",
    "# Softdrop\n",
    "\n",
    "class myJet(object):\n",
    "    def __init__(self,px,py,pz):\n",
    "        self.px = px; self.py = py; self.pz = pz; self.pt = (px**2+py**2)**(1/2)\n",
    "        self.phi = math.atan2(py,px); self.eta = -math.log(math.tan(math.atan2(self.pt,self.pz)/2));\n",
    "\n",
    "class Node(object):\n",
    "    def __init__(self,data):\n",
    "        self.data = data\n",
    "        self.children = []\n",
    "    def add_child(self,obj):\n",
    "        self.children.append(obj)\n",
    "\n",
    "def softdrop(jcon,z=0.1,debug = 0):\n",
    "    #Takes the constituents of a jet, and softdrops it.\n",
    "    #First, we need to step through the jet and build the tree of clustering\n",
    "    #Since we are reclustering the whole thing; just take R = 1; i.e. dont need to think about it\n",
    "    def distance(con1,con2):\n",
    "        return R(con1,con2)**2\n",
    "    pseudojets = []\n",
    "    nodes = []\n",
    "    for con in jcon:\n",
    "        x = Node([con,1])\n",
    "        #pseudojets.append(x)\n",
    "        nodes.append(x) #1 means its still a pseudojet; i.e. not been clustered\n",
    "    def how_many_pseudo(nodes):\n",
    "        how_many = 0\n",
    "        for node in nodes:\n",
    "            if node.data[1] == 1:\n",
    "                how_many = how_many + 1\n",
    "        return how_many\n",
    "    if debug == 1:\n",
    "        print(\"len(nodes) : \" + str(len(nodes)))\n",
    "        #print(nodes)\n",
    "    rep = 0\n",
    "    while how_many_pseudo(nodes) > 1:\n",
    "        #print(how_many_pseudo(nodes))\n",
    "        min_distance = float(\"inf\")\n",
    "        min_index = [0,0]\n",
    "        for i in range(0,len(nodes)):\n",
    "            if nodes[i].data[1] == 0: #Its already part of something else\n",
    "                continue\n",
    "            for j in range(i+1,len(nodes)):\n",
    "                if nodes[j].data[1] == 0:\n",
    "                    continue\n",
    "                if distance(nodes[i].data[0],nodes[j].data[0]) < min_distance:\n",
    "                    min_index[0] = i; min_index[1] = j; \n",
    "                    min_distance = distance(nodes[i].data[0],nodes[j].data[0])\n",
    "        i = min_index[0];j=min_index[1];\n",
    "        new_node = Node([myJet(nodes[i].data[0].px+nodes[j].data[0].px,\n",
    "                           nodes[i].data[0].py+nodes[j].data[0].py,\n",
    "                           nodes[i].data[0].pz+nodes[j].data[0].pz),1])\n",
    "        new_node.add_child(nodes[i])\n",
    "        new_node.add_child(nodes[j])\n",
    "        nodes.append(new_node)\n",
    "        nodes[i].data[1] = 0\n",
    "        nodes[j].data[1] = 0\n",
    "    \n",
    "    #print(nodes)\n",
    "\n",
    "    to_check = [] #nodes to check\n",
    "    for i in range(len(nodes)):\n",
    "        if nodes[i].data[1] == 1:\n",
    "            to_check.append(nodes[i])\n",
    "    softcon = []\n",
    "    while len(to_check) > 0:\n",
    "        #print(to_check)\n",
    "        our_childs = to_check[0].children\n",
    "        #print(our_childs)\n",
    "        if len(our_childs) == 0:\n",
    "            softcon.append(to_check[0].data[0])\n",
    "            to_check.pop(0)\n",
    "            continue\n",
    "        if min(our_childs[0].data[0].pt,our_childs[1].data[0].pt)/  \\\n",
    "                        (our_childs[0].data[0].pt+our_childs[1].data[0].pt) > z:\n",
    "            to_check.append(our_childs[0])\n",
    "            to_check.append(our_childs[1])\n",
    "        elif our_childs[0].data[0].pt > our_childs[1].data[0].pt:\n",
    "            to_check.append(our_childs[0])\n",
    "        else:\n",
    "            to_check.append(our_childs[1])\n",
    "        to_check.pop(0)\n",
    "    return softcon\n",
    "\n",
    "# Normalize and zero-center any image\n",
    "def zero_center_and_normalize(background_images, signal_images):\n",
    "    tmp_av = np.average(np.concatenate((background_images, signal_images)), axis=0)\n",
    "    tmp_sd = np.std(np.concatenate((background_images, signal_images)), axis=0)\n",
    "    for i in range(len(background_images)):\n",
    "        background_images[i] = np.divide((background_images[i] - tmp_av), (tmp_sd+1e-5)) #perhaps add some r to temp_sd to suppress noise\n",
    "    for i in range(len(signal_images)):\n",
    "        signal_images[i] = np.divide((signal_images[i] - tmp_av), (tmp_sd+1e-5))#/tmp_sd\n",
    "    return background_images, signal_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 Keras",
   "language": "python",
   "name": "python_3_keras"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
