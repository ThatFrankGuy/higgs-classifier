{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# File processor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "csv_decoder.py is a packaged version of Josh's methods reading .csv generated by his c++ showering code.\n",
    "save_and_load.py specifically saves and loads all essential lists/images used in the analysis to np.save formats.\n",
    "\n",
    "This notebook shows the example use of methods in csv_decoder.py and save_and_load.py. It reads .csv files containing particle eta, phi, pt, ... produced by Josh's showering program, performs fast detector simulation to generate detector & jet images, and saves to faster np.save format. The save(), load() and load_cluster() methods are saved in "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Import local libraries\n",
    "import csv_decoder\n",
    "import save_and_load\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jet and event image setting\n",
    "width = 40\n",
    "height = 40 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading in Josh's files; background is a single large file (pT cut must be 1 here for Josh's sample)\n",
    "# This read produces event_list (collection of raw vectors) and event images\n",
    "\n",
    "# This will be used to test saving mechanisms.\n",
    "\n",
    "print('Loading background events')\n",
    "background_event_list,background_mass_list,background_image_list,num_background_files = \\\n",
    "    csv_decoder.load_events(\"actual\", max_Files=1,path=\"/data1/users/jzlin/MLM/background_7413/\",\\\n",
    "                contains=\"_actual\",pt_cut=1, width=width, height=height)\n",
    "num_background_files = 15693\n",
    "\n",
    "print('Loading signal events')\n",
    "signal_event_list,signal_mass_list,signal_image_list,num_signal_files = \\\n",
    "    csv_decoder.load_events(\"actual\", max_Read = len(background_event_list),path=\"/data1/users/jzlin/MLM/heavy_signal/\",\\\n",
    "                contains=\"_signal\",pt_cut=1, width=width, height=height)\n",
    "\n",
    "# Check size of dataset\n",
    "print(len(background_mass_list),len(signal_mass_list))\n",
    "\n",
    "# Zero centering and normalizing\n",
    "background_image_list, signal_image_list = csv_decoder.zero_center_and_normalize(background_image_list,signal_image_list)\n",
    "\n",
    "# This is not used\n",
    "background_mass_window = np.logical_and(np.array(background_mass_list) > 115,np.array(background_mass_list) < 135)\n",
    "\n",
    "# Cluster events_lists into jets. The results are named background/signal_event_list_clustered\n",
    "print('Clustering')\n",
    "background_event_list_clustered = csv_decoder.cluster_event(background_event_list)\n",
    "signal_event_list_clustered = csv_decoder.cluster_event(signal_event_list)\n",
    "\n",
    "# Reclustering the events (i.e. clustering within events)\n",
    "print('Reclustering')\n",
    "background_reclustered = csv_decoder.recluster_event(background_event_list_clustered)\n",
    "signal_reclustered = csv_decoder.recluster_event(signal_event_list_clustered)\n",
    "\n",
    "# Produce jet images, the zero-center and normalize\n",
    "print('Producing jet images')\n",
    "background_recluster_images = csv_decoder.return_fine_image_list_reclustered(background_event_list,\n",
    "                                                           background_reclustered,0.8, width=width, height=height)\n",
    "signal_recluster_images = csv_decoder.return_fine_image_list_reclustered(signal_event_list,\n",
    "                                                           signal_reclustered,0.8, width=width, height=height)\n",
    "\n",
    "background_recluster_images, signal_recluster_images = csv_decoder.zero_center_and_normalize(background_recluster_images, signal_recluster_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weight calculation for Josh's sample\n",
    "backgroundCross = 2.048e-06 # Cross-section of processes in millibarns, NOT USED\n",
    "\n",
    "actual_background_cross=2.84e-9 # In barns, used in background weight\n",
    "average_number_accepted=2162 # Used in background weight\n",
    "\n",
    "actual_signal_cross = np.average([1.738e-14,1.7277e-14]) # Used in signal weight\n",
    "signal_accepted = np.average([8708-189,8827-172]) # Used in signal weight \n",
    "\n",
    "background_weight = actual_background_cross*35.9*1e15/(average_number_accepted*num_background_files)\n",
    "signal_weight = actual_signal_cross*35.9*1e15/(signal_accepted*num_signal_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time: 19.26s\n",
    "save_and_load.save('test-all', background_event_list, signal_event_list, background_mass_list, signal_mass_list,\\\n",
    "        background_weight, signal_weight, background_image_list, signal_image_list,\\\n",
    "        background_recluster_images, signal_recluster_images)\n",
    "new_background_event_list, new_signal_event_list, new_background_mass_list, new_signal_mass_list,\\\n",
    "        new_background_weight, new_signal_weight, new_background_image_list, new_signal_image_list,\\\n",
    "        new_background_recluster_images, new_signal_recluster_images = save_and_load.load('test-all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'background_mass_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-a035cfb1b837>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray_equal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_background_mass_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackground_mass_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray_equal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_signal_mass_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignal_mass_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray_equal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_background_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackground_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray_equal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_signal_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignal_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray_equal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_background_image_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackground_image_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'background_mass_list' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "print(np.array_equal(new_background_mass_list, background_mass_list))\n",
    "print(np.array_equal(new_signal_mass_list, signal_mass_list))\n",
    "print(np.array_equal(new_background_weight, background_weight))\n",
    "print(np.array_equal(new_signal_weight, signal_weight))\n",
    "print(np.array_equal(new_background_image_list, background_image_list))\n",
    "print(np.array_equal(new_signal_image_list, signal_image_list))\n",
    "print(np.array_equal(new_background_recluster_images, background_recluster_images))\n",
    "print(np.array_equal(new_signal_recluster_images, signal_recluster_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(background_mass_list)+len(signal_mass_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 Keras",
   "language": "python",
   "name": "python_3_keras"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
